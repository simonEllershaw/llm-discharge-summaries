{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://htmlpreview.github.io/?https://github.com/CogStack/MedCATtutorials/blob/main/notebooks/specialised/Preprocessing_SNOMED_CT.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from medcat.utils.preprocess_snomed import Snomed\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.schemas.mimic import Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOMED_PATH = (\n",
    "    Path.cwd().parent / \"data\" / \"SnomedCT_InternationalRF2_PRODUCTION_20230731T120000Z\"\n",
    ")\n",
    "MODEL_DIR = Path.cwd().parent / \"models\"\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "GT_DATA_PATH = DATA_DIR / \"train.pkl\"\n",
    "\n",
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GT_DATA_PATH, \"rb\") as in_file:\n",
    "    gt_dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "len(gt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing SNOMED CT for MedCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sowmed = Snomed(str(SNOMED_PATH))\n",
    "sowmed.uk_ext = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sowmed.to_concept_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description_type_ids\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset = df[df['description_type_ids'].isin(['finding', 'disorder'])]\n",
    "df_subset = df[df[\"name_status\"] == \"A\"]\n",
    "len(df_subset), len(df_subset[\"cui\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = English().tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(tokenizer.vocab, \"LOWER\")\n",
    "for cui, group_df in tqdm(df_subset.groupby(\"cui\")):\n",
    "    matcher.add(cui, list(tokenizer.pipe(group_df[\"name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(tokenizer(\"stroke\"), as_spans=True)\n",
    "matches[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hits = 0\n",
    "num_examples = 0\n",
    "misses = set()\n",
    "for sample in tqdm(gt_dataset):\n",
    "    for para in sample.discharge_summary.bhc_paragraphs:\n",
    "        if not para.heading:\n",
    "            continue\n",
    "        clean_heading = para.heading\n",
    "        heading_match = re.search(r\"[a-zA-Z]\", para.heading)\n",
    "        clean_heading = (\n",
    "            para.heading[heading_match.start() :] if heading_match else para.heading\n",
    "        )\n",
    "        # clean_heading = clean_heading.replace('/', ' ')\n",
    "        matches = matcher(tokenizer(clean_heading), as_spans=True)\n",
    "        # if not(any(word in clean_heading.lower() for word in {\"fen\", \"communication\", \"access\", \"code\"})):\n",
    "        num_examples += 1\n",
    "        if matches:\n",
    "            num_hits += 1\n",
    "        else:\n",
    "            misses.add(clean_heading.lower().strip())\n",
    "\n",
    "num_hits / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher(tokenizer(\"uti\"), as_spans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"name\"].str.contains(\" UTI \", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_names = df[df[\"name_status\"] == \"P\"].set_index(\"cui\")\n",
    "len(df_p_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ids = [\n",
    "    df_p_names.loc[match.label_].description_type_ids\n",
    "    for sample in tqdm(gt_dataset)\n",
    "    for para in sample.discharge_summary.bhc_paragraphs\n",
    "    for match in matcher(tokenizer(para.heading), as_spans=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(type_ids)\n",
    "counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples, len(misses), num_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.matcher import Matcher\n",
    "\n",
    "# token_matcher = Matcher(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cui, group_df in tqdm(df_subset.groupby(\"cui\")):\n",
    "#     pattern = [[{\"LOWER\": {\"FUZZY\": token.text}} for token in pattern_doc]\n",
    "#     for pattern_doc in tokenizer.pipe(group_df[\"name\"])]\n",
    "#     token_matcher.add(cui, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_hits = 0\n",
    "# num_examples = 0\n",
    "# misses = set()\n",
    "# for sample in tqdm(gt_dataset):\n",
    "#     for para in sample.discharge_summary.bhc_paragraphs:\n",
    "#         if not para.heading:\n",
    "#             continue\n",
    "#         clean_heading = para.heading\n",
    "#         # heading_match = re.search(r'[a-zA-Z]', para.heading)\n",
    "#         # clean_heading = para.heading[heading_match.start():] if heading_match else para.heading\n",
    "#         # clean_heading = clean_heading.replace('/', ' ')\n",
    "#         matches = token_matcher(tokenizer(clean_heading), as_spans=True)\n",
    "#         # if not(any(word in clean_heading.lower() for word in {\"fen\", \"communication\", \"access\", \"code\"})):\n",
    "#         num_examples += 1\n",
    "#         if matches:\n",
    "#             num_hits += 1\n",
    "#         else:\n",
    "#             misses.add(clean_heading.lower().strip())\n",
    "\n",
    "# num_hits / num_examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
