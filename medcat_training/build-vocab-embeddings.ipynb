{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from medcat.cdb_maker import CDBMaker\n",
    "from medcat.config import Config\n",
    "from medcat.utils.make_vocab import MakeVocab\n",
    "from medcat.utils.preprocess_wiki import clean_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a CDB to and embedding set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wikipedia\n",
    "This step can take hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = \"../data/enwiki-20230601-pages-articles-multistream.xml.bz2\"\n",
    "corpus = \"../data/wikipedia_corpus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wiki(wiki, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a fresh vocab\n",
    "Generate a set of word embeddings from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def articles(file):\n",
    "    # Generator function to read wikipedia article by article, as it is too large to read into memory.\n",
    "    with Path(file).open() as file:\n",
    "        buf = \"\"\n",
    "        for line in file:\n",
    "            if line == \"\":\n",
    "                buf += file.readline() + \"\\n\"\n",
    "            else:\n",
    "                yield buf\n",
    "                buf = \"\"\n",
    "\n",
    "\n",
    "wiki_entries = articles(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_maker = MakeVocab(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_maker.make(wiki_entries, \"/home/james/repositories/miade/data/wikipedia_vocab\")\n",
    "vocab_maker.add_vectors(\"/home/james/repositories/miade/data/wikipedia_vocab/data.txt\")\n",
    "vocab = vocab_maker.vocab\n",
    "vocab.make_unigram_table()\n",
    "vocab.save(\"/home/james/repositories/miade/data/wikipedia_vocab/vocab.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a default \"maker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.general[\"spacy_model\"] = \"en_core_web_md\"\n",
    "maker = CDBMaker(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
