{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from random import Random\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "import jsonschema\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from discharge_summaries.openai_llm.chat_models import AzureOpenAIChatModel\n",
    "from discharge_summaries.openai_llm.prompts import (\n",
    "    generate_rcp_system_message,\n",
    "    generate_rcp_user_message,\n",
    ")\n",
    "from discharge_summaries.schemas.mimic import PhysicianNote\n",
    "from discharge_summaries.schemas.rcp_guidelines import RCPGuidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_ENGINE = \"gpt-4\"\n",
    "AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "TOKENIZER_NAME = \"cl100k_base\"\n",
    "EXAMPLE_DIR = Path.cwd() / \"examples\"\n",
    "OUTPUT_DIR = Path.cwd() / \"output\"\n",
    "\n",
    "SNOMED_DIR = Path.cwd().parent / \"data\" / \"snomed\"\n",
    "PHRASE_MATCHER_FPATH = SNOMED_DIR / \"snomed_phrase_matcher_full.pkl\"\n",
    "\n",
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "PHYSICIAN_NOTE_FPATH = MIMIC_III_DIR / \"physician_notes_mimic.csv\"\n",
    "\n",
    "SAMPLE_SIZE = 5\n",
    "RANDOM_SEED = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_schema = RCPGuidelines.schema()\n",
    "example = json.loads((EXAMPLE_DIR / \"example.json\").read_text())\n",
    "jsonschema.validate(example, rcp_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_keys_recursive(d: Union[List, Dict], keys: Set[str]):\n",
    "    if isinstance(d, dict):\n",
    "        for key in list(d.keys()):\n",
    "            if key in keys:\n",
    "                del d[key]\n",
    "            else:\n",
    "                remove_keys_recursive(d[key], keys)\n",
    "    elif isinstance(d, list):\n",
    "        for item in d:\n",
    "            remove_keys_recursive(item, keys)\n",
    "    return d\n",
    "\n",
    "\n",
    "# Remove keys \"title\" and \"required\" recursively\n",
    "simplified_rcp_schema = remove_keys_recursive(\n",
    "    deepcopy(rcp_schema), {\"title\", \"required\"}\n",
    ")\n",
    "simplified_rcp_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = pd.read_csv(PHYSICIAN_NOTE_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm_ids = notes_df[\"HADM_ID\"].unique().tolist()\n",
    "sample_hadm_ids = Random(RANDOM_SEED).sample(hadm_ids, SAMPLE_SIZE)\n",
    "sample_hadm_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hadm_id = sample_hadm_ids[0]\n",
    "physician_notes = [\n",
    "    PhysicianNote(text=row[\"TEXT\"], hadm_id=row[\"HADM_ID\"], timestamp=row[\"CHARTTIME\"])\n",
    "    for _, row in notes_df[notes_df[\"HADM_ID\"] == sample_hadm_id].iterrows()\n",
    "]\n",
    "physician_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_note_lines(notes: List[PhysicianNote]) -> List[PhysicianNote]:\n",
    "    seen_lines = set()\n",
    "    deduplicated_notes = []\n",
    "    for note in notes:\n",
    "        deduplicated_lines = []\n",
    "        for line in note.text.split(\"\\n\"):\n",
    "            if line == \"\" or line in seen_lines:\n",
    "                pass\n",
    "            else:\n",
    "                seen_lines.add(line)\n",
    "                deduplicated_lines.append(line)\n",
    "        if deduplicated_lines:\n",
    "            deduplicated_notes.append(\n",
    "                note.copy(update={\"text\": \"\\n\".join(deduplicated_lines)})\n",
    "            )\n",
    "    return deduplicated_notes\n",
    "\n",
    "\n",
    "deduplicated_notes = deduplicate_note_lines(physician_notes)\n",
    "deduplicated_notes = sorted(deduplicated_notes, key=lambda x: x.timestamp)\n",
    "len(physician_notes), len(deduplicated_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = generate_rcp_system_message(simplified_rcp_schema, example)\n",
    "print(system_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = generate_rcp_user_message(physician_notes)\n",
    "print(user_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(TOKENIZER_NAME)\n",
    "for message in [system_message, user_message]:\n",
    "    print(len(tokenizer.encode(message.content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAIChatModel(\n",
    "    api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=AZURE_API_VERSION,\n",
    "    engine=AZURE_ENGINE,\n",
    "    temperature=0,\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.query([system_message, user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(OUTPUT_DIR / f\"mimic_{int(sample_hadm_id)}.json\").write_text(\n",
    "    json.dumps(json.loads(response.content), indent=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"mimic_{int(sample_hadm_id)}.json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
