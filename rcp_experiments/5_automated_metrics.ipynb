{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED_DIR = Path.cwd() / \"outputs\" / \"annotated\"\n",
    "RAW_GENERATED_DIR = Path.cwd() / \"outputs\" / \"output_eval_v3\"\n",
    "GPT_4_TURBO_INPUT_COST_PER_1K = 0.01\n",
    "GPT_4_TURBO_OUTPUT_COST_PER_1K = 0.03\n",
    "TOKENIZER_NAME = \"cl100k_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm_id_to_discharge_summary = {\n",
    "    directory.stem: json.loads((directory / \"discharge_summary.json\").read_text())\n",
    "    for directory in RAW_GENERATED_DIR.iterdir()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimter = \"\\n\" + \"*\" * 80 + \"\\n\"\n",
    "hadm_id_to_messages = {\n",
    "    directory.stem: list((directory / \"raw_messages.txt\").read_text().split(delimter))\n",
    "    for directory in RAW_GENERATED_DIR.iterdir()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_json_strings(json_object):\n",
    "    strings_list = []\n",
    "\n",
    "    def process_object(obj):\n",
    "        if isinstance(obj, str):\n",
    "            strings_list.append(obj)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                process_object(item)\n",
    "        elif isinstance(obj, dict):\n",
    "            for value in obj.values():\n",
    "                process_object(value)\n",
    "\n",
    "    process_object(json_object)\n",
    "    return strings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_extractive_sentences = 0\n",
    "num_generated_sentences = 0\n",
    "\n",
    "for hadm_id in hadm_id_to_messages.keys():\n",
    "    discharge_summary_json = hadm_id_to_discharge_summary[hadm_id]\n",
    "    physician_notes_text_lowercase = hadm_id_to_messages[hadm_id][3].lower()\n",
    "\n",
    "    json_strings = find_json_strings(discharge_summary_json)\n",
    "    json_sentences_lowercase = [\n",
    "        sentence.lower()\n",
    "        for item in json_strings\n",
    "        for sentence in item.split(\". \")\n",
    "        if sentence != \"\"\n",
    "    ]\n",
    "\n",
    "    num_extractive_sentences += sum(\n",
    "        1\n",
    "        for sentence_lowercase in json_sentences_lowercase\n",
    "        if sentence_lowercase in physician_notes_text_lowercase\n",
    "    )\n",
    "    num_generated_sentences += len(json_sentences_lowercase)\n",
    "\n",
    "num_extractive_sentences / num_generated_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile: 25th 50th 75th\n",
    "abstract length\n",
    "# characters 825 1,263 1,679\n",
    "# tokens 177 275 383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(TOKENIZER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = next(iter(hadm_id_to_messages.values()))\n",
    "prompt_token_length = sum(len(tokenizer.encode(message)) for message in messages[:3])\n",
    "prompt_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_message_length_token = []\n",
    "note_message_length_char = []\n",
    "for messages in hadm_id_to_messages.values():\n",
    "    note_message = messages[3]\n",
    "    note_message_length_char.append(len(note_message))\n",
    "    note_message_length_token.append(len(tokenizer.encode(note_message)))\n",
    "\n",
    "print(\n",
    "    np.percentile(note_message_length_char, [25, 50, 75]),\n",
    "    np.max(note_message_length_char),\n",
    ")\n",
    "print(\n",
    "    np.percentile(note_message_length_token, [25, 50, 75]),\n",
    "    np.max(note_message_length_token),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_times = [\n",
    "    float(messages[-2].split(\": \")[1]) for messages in hadm_id_to_messages.values()\n",
    "]\n",
    "\n",
    "print(np.percentile(completion_times, [25, 50, 75]), np.max(completion_times))\n",
    "print(np.percentile(completion_times, [25, 50, 75]), np.max(completion_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for messages in hadm_id_to_messages.values():\n",
    "    num_input_tokens = sum(len(tokenizer.encode(message)) for message in messages[:4])\n",
    "    num_output_tokens = len(tokenizer.encode(messages[4]))\n",
    "    costs.append(\n",
    "        num_input_tokens / 1000 * GPT_4_TURBO_INPUT_COST_PER_1K\n",
    "        + num_output_tokens / 1000 * GPT_4_TURBO_OUTPUT_COST_PER_1K\n",
    "    )\n",
    "print(np.percentile(costs, [25, 50, 75]), np.max(costs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
