{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "import jsonschema\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from discharge_summaries.openai_llm.chat_models import AzureOpenAIChatModel\n",
    "from discharge_summaries.openai_llm.prompts import (\n",
    "    generate_rcp_system_message,\n",
    "    generate_rcp_user_message,\n",
    ")\n",
    "from discharge_summaries.schemas.mimic import PhysicianNote\n",
    "from discharge_summaries.schemas.rcp_guidelines import RCPGuidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_ENGINE = \"gpt-4\"\n",
    "AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "TOKENIZER_NAME = \"cl100k_base\"\n",
    "EXAMPLE_DIR = Path.cwd() / \"examples\"\n",
    "OUTPUT_DIR = Path.cwd() / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_schema = RCPGuidelines.schema()\n",
    "example = json.loads((EXAMPLE_DIR / \"example.json\").read_text())\n",
    "jsonschema.validate(example, rcp_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_keys_recursive(d: Union[List, Dict], keys: Set[str]):\n",
    "    if isinstance(d, dict):\n",
    "        for key in list(d.keys()):\n",
    "            if key in keys:\n",
    "                del d[key]\n",
    "            else:\n",
    "                remove_keys_recursive(d[key], keys)\n",
    "    elif isinstance(d, list):\n",
    "        for item in d:\n",
    "            remove_keys_recursive(item, keys)\n",
    "    return d\n",
    "\n",
    "\n",
    "# Remove keys \"title\" and \"required\" recursively\n",
    "simplified_rcp_schema = remove_keys_recursive(\n",
    "    deepcopy(rcp_schema), {\"title\", \"required\"}\n",
    ")\n",
    "simplified_rcp_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCP Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = pd.read_excel(\n",
    "    Path.cwd().parent\n",
    "    / \"data\"\n",
    "    / \"rcp\"\n",
    "    / \"5. Activity-practice discharge summary writing task_0.xlsx\",\n",
    "    sheet_name=\"Notes\",\n",
    "    header=4,\n",
    ")\n",
    "notes_df.rename({\"Unnamed: 0\": \"timestamp\", \"Unnamed: 1\": \"text\"}, axis=1, inplace=True)\n",
    "notes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_rows = notes_df.isnull().all(axis=1)\n",
    "consecutive_blank_rows = blank_rows & blank_rows.shift(-1)\n",
    "\n",
    "split_dfs = []\n",
    "start_index = 0\n",
    "for end_index in consecutive_blank_rows[consecutive_blank_rows].index:\n",
    "    split_dfs.append(notes_df.iloc[start_index:end_index])\n",
    "    start_index = end_index + 2\n",
    "split_dfs.append(notes_df.iloc[start_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "\n",
    "for split_df in split_dfs:\n",
    "    date_string = split_df[\"timestamp\"].tolist()[0]\n",
    "    date_string_excl_day = date_string.split(\" \", 1)[1]\n",
    "    timestamp = datetime.strptime(date_string_excl_day, \"%d %b %Y %H:%M\")\n",
    "    notes.append(\n",
    "        PhysicianNote(\n",
    "            timestamp=timestamp.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "            text=\"\\n\".join(split_df[\"text\"].dropna().tolist()),\n",
    "            hadm_id=\"0\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_note_lines(notes: List[PhysicianNote]) -> List[PhysicianNote]:\n",
    "    seen_lines = set()\n",
    "    deduplicated_notes = []\n",
    "    for note in notes:\n",
    "        deduplicated_lines = []\n",
    "        for line in note.text.split(\"\\n\"):\n",
    "            if line == \"\" or line in seen_lines:\n",
    "                pass\n",
    "            else:\n",
    "                seen_lines.add(line)\n",
    "                deduplicated_lines.append(line)\n",
    "        if deduplicated_lines:\n",
    "            deduplicated_notes.append(\n",
    "                note.copy(update={\"text\": \"\\n\".join(deduplicated_lines)})\n",
    "            )\n",
    "    return deduplicated_notes\n",
    "\n",
    "\n",
    "deduplicated_notes = deduplicate_note_lines(notes)\n",
    "deduplicated_notes = sorted(deduplicated_notes, key=lambda x: x.timestamp)\n",
    "len(notes), len(deduplicated_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = generate_rcp_system_message(simplified_rcp_schema, example)\n",
    "print(system_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = generate_rcp_user_message(notes)\n",
    "print(user_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(TOKENIZER_NAME)\n",
    "for message in [system_message, user_message]:\n",
    "    print(len(tokenizer.encode(message.content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAIChatModel(\n",
    "    api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=AZURE_API_VERSION,\n",
    "    engine=AZURE_ENGINE,\n",
    "    temperature=0,\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.query([system_message, user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(OUTPUT_DIR / \"rcp_example_1.json\").write_text(\n",
    "    json.dumps(json.loads(response.content), indent=4)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
