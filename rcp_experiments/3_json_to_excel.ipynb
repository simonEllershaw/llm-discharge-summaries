{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from openpyxl.styles import Font\n",
    "\n",
    "from discharge_summaries.schemas.mimic import PhysicianNote\n",
    "from discharge_summaries.schemas.rcp_guidelines import RCPGuidelines\n",
    "from discharge_summaries.utils.deduplicate import deduplicate_physician_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_OUTPUT_DIR = Path.cwd() / \"output_eval_v3\"\n",
    "HUMAN_OUTPUT_DIR = Path.cwd() / \"output_human_v3\"\n",
    "EXAMPLE_DIR = Path.cwd() / \"examples\"\n",
    "\n",
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "PHYSICIAN_NOTE_FPATH = MIMIC_III_DIR / \"physician_notes_mimic.csv\"\n",
    "HADM_IDS = [154417, 115949, 103411, 157928, 179134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = pd.read_csv(PHYSICIAN_NOTE_FPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_json_to_df(response_json: Dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for section, fields_and_values in response_json.items():\n",
    "        if isinstance(fields_and_values, dict):\n",
    "            for field, value in fields_and_values.items():\n",
    "                if isinstance(value, str):\n",
    "                    rows.append([section, field, value])\n",
    "                elif isinstance(value, list):\n",
    "                    if not value:\n",
    "                        rows.append([section, field, \"\"])\n",
    "                    for item in value:\n",
    "                        rows.append([section, field, item])\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "        elif isinstance(fields_and_values, list):\n",
    "            if not fields_and_values:\n",
    "                rows.append([section, field, \"\"])\n",
    "            for item_idx, item in enumerate(fields_and_values):\n",
    "                if isinstance(item, dict):\n",
    "                    for field, value in item.items():\n",
    "                        if isinstance(value, str):\n",
    "                            rows.append([section, f\"{field} {item_idx}\", value])\n",
    "                        else:\n",
    "                            raise NotImplementedError\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "        rows.append([\"\", \"\", \"\"])\n",
    "    return pd.DataFrame(rows, columns=[\"Section\", \"Field\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rows_df(rows_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows_df[\"Section\"] = rows_df[\"Section\"].drop_duplicates(keep=\"first\")\n",
    "    rows_df[\"Field\"] = rows_df[\"Field\"].drop_duplicates(keep=\"first\")\n",
    "\n",
    "    rows_df.fillna(\"\", inplace=True)\n",
    "    rows_df[[\"Section\", \"Field\"]] = rows_df[[\"Section\", \"Field\"]].applymap(\n",
    "        lambda x: x.replace(\"_\", \" \").title()\n",
    "    )\n",
    "    return rows_df\n",
    "\n",
    "\n",
    "def fill_empty_values(rows_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows_df.loc[rows_df[\"Field\"].ne(\"\") & rows_df[\"Value\"].eq(\"\"), \"Value\"] = (\n",
    "        \"Information not found in notes\"\n",
    "    )\n",
    "    return rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_excel(ws):\n",
    "    ws.insert_rows(1)\n",
    "    ws.cell(row=1, column=1, value=\"GPT Discharge Summary\")\n",
    "    ws.cell(row=1, column=5, value=\"Evaluation\")\n",
    "\n",
    "    for idx, eval_heading in enumerate(\n",
    "        [\n",
    "            \"Missed- Severe\",\n",
    "            \"Missed- Minor\",\n",
    "            \"Added- Hallucination\",\n",
    "            \"Added- Not relevant\",\n",
    "            \"Explanation of Error\",\n",
    "            \"Comments\",\n",
    "        ]\n",
    "    ):\n",
    "        ws.cell(row=2, column=5 + idx, value=eval_heading)\n",
    "\n",
    "    for c in ws[\"A\"]:\n",
    "        c.font = Font(bold=True, sz=11)\n",
    "    for cell in ws.iter_rows(min_row=2, max_row=2, values_only=True):\n",
    "        c.font = Font(bold=True, sz=12)\n",
    "    for cell in ws.iter_rows(min_row=1, max_row=1, values_only=True):\n",
    "        c.font = Font(bold=True, sz=14)\n",
    "\n",
    "    for column in ws.columns:\n",
    "        ws.column_dimensions[column[0].column_letter].width = 40\n",
    "    ws.column_dimensions[\"C\"].width = 80\n",
    "\n",
    "    for row in ws.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.alignment = openpyxl.styles.Alignment(wrap_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_response_json_to_excel(response_json_fpath: Path, excel_fpath: Path):\n",
    "    response_json = json.loads(response_json_fpath.read_text())\n",
    "    discharge_summary = RCPGuidelines(**response_json)\n",
    "\n",
    "    rows_df = response_json_to_df(discharge_summary.dict())\n",
    "    rows_df = format_rows_df(rows_df)\n",
    "    rows_df = fill_empty_values(rows_df)\n",
    "\n",
    "    rows_df.to_excel(excel_fpath, index=False)\n",
    "\n",
    "    wb = openpyxl.load_workbook(excel_fpath)\n",
    "    format_excel(wb.active)\n",
    "    wb.save(excel_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hadm_id_notes_df_to_word(notes_df, hadm_id, deduplicate=False) -> Document:\n",
    "    physician_notes = [\n",
    "        PhysicianNote(\n",
    "            hadm_id=row[\"HADM_ID\"],\n",
    "            title=row[\"DESCRIPTION\"],\n",
    "            timestamp=row[\"CHARTTIME\"],\n",
    "            text=row[\"TEXT\"],\n",
    "        )\n",
    "        for _, row in notes_df[notes_df[\"HADM_ID\"] == hadm_id].iterrows()\n",
    "    ]\n",
    "    if deduplicate:\n",
    "        physician_notes = deduplicate_physician_notes(physician_notes)\n",
    "\n",
    "    doc = Document()\n",
    "\n",
    "    doc.add_heading(f\"Physician Notes Patient ID {hadm_id}\", level=1)\n",
    "    for note in physician_notes:\n",
    "        date_uk_format = datetime.strptime(\n",
    "            note.timestamp, \"%Y-%m-%d %H:%M:%S\"\n",
    "        ).strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "        doc.add_heading(f\"{note.title}: {date_uk_format}\", level=2)\n",
    "        doc.add_paragraph(note.text)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_json_path = GPT_OUTPUT_DIR / \"179544\" / \"discharge_summary.json\"\n",
    "faulty_json = json.loads(faulty_json_path.read_text())\n",
    "faulty_json[\"GP_practice\"] = {\"GP_name\": \"\"}\n",
    "faulty_json_path.write_text(json.dumps(faulty_json, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hadm_id_output_dir in GPT_OUTPUT_DIR.iterdir():\n",
    "    hadm_id = hadm_id_output_dir.stem\n",
    "\n",
    "    human_output_hadm_id_dir = HUMAN_OUTPUT_DIR / hadm_id\n",
    "    human_output_hadm_id_dir.mkdir(exist_ok=True)\n",
    "    # write_response_json_to_excel(\n",
    "    #     (EXAMPLE_DIR / \"blank.json\"), (hadim_output_dir / f\"template_{hadm_id}.xlsx\")\n",
    "    # )\n",
    "\n",
    "    write_response_json_to_excel(\n",
    "        (hadm_id_output_dir / \"discharge_summary.json\"),\n",
    "        (human_output_hadm_id_dir / f\"discharge_summary_{hadm_id}.xlsx\"),\n",
    "    )\n",
    "\n",
    "    doc = hadm_id_notes_df_to_word(notes_df, int(hadm_id), deduplicate=False)\n",
    "    doc.save(human_output_hadm_id_dir / f\"physician_notes_{hadm_id}.docx\")\n",
    "\n",
    "    # doc = hadm_id_notes_df_to_word(notes_df, hadm_id, deduplicate=True)\n",
    "    # doc.save(hadim_output_dir / f\"physician_notes_deduplicated_{hadm_id}.docx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
