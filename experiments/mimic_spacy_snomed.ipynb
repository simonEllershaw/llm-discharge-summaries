{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.preprocessing.preprocess_snomed import Snomed\n",
    "from discharge_summaries.schemas.mimic import Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "TRAINING_DATASET_PATH = DATA_DIR / \"train.pkl\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "RANDOM_SEED = 23\n",
    "SNOMED_DIR = (\n",
    "    Path.cwd().parent\n",
    "    / \"data\"\n",
    "    / \"SnomedCT_InternationalRF2_PRODUCTION_20230731T120000Z\"\n",
    "    / \"Snapshot\"\n",
    "    / \"Terminology\"\n",
    ")\n",
    "\n",
    "description_file = SNOMED_DIR / \"sct2_Description_Snapshot-en_INT_20230731.txt\"\n",
    "relation_file = SNOMED_DIR / \"sct2_Relationship_Snapshot_INT_20230731.txt\"\n",
    "\n",
    "SPACY_MODEL = \"en_core_md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_DATASET_PATH, \"rb\") as in_file:\n",
    "    dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "dataset = dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = Counter(\n",
    "    title\n",
    "    for record in tqdm(dataset)\n",
    "    for title in re.findall(\n",
    "        \"(?<=\\n\\n)[a-zA-Z ]*?(?=:.*?\\n)\", record.discharge_summary.text\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_titles = [\n",
    "    title for title, count in titles.most_common() if count > len(dataset) * 0.95\n",
    "]\n",
    "common_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_title_to_body = []\n",
    "for record in tqdm(dataset):\n",
    "    title_to_body = {}\n",
    "    for section in re.split(\n",
    "        f\"\\n\\n(?=(?:{'|'.join(common_titles)}):.*?\\n)\", record.discharge_summary.text\n",
    "    ):\n",
    "        title_and_body = section.split(\":\", maxsplit=1)\n",
    "        title_to_body[title_and_body[0]] = title_and_body[1].strip()\n",
    "    dataset_title_to_body.append(title_to_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed = Snomed(description_file, relation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_cuis = [\n",
    "    \"404684003\",\n",
    "    \"118956008\",\n",
    "    \"384760004\",\n",
    "    # \"365870005\",\n",
    "    # \"169443000\",\n",
    "    # \"726711005\",\n",
    "    # \"311788003\",\n",
    "    # \"251149006\",\n",
    "    # \"739122008\"\n",
    "]\n",
    "[snomed.get_preferred_term(cui) for cui in parent_cuis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis_of_interest = {\n",
    "    child_cui\n",
    "    for parent_cui in parent_cuis\n",
    "    for child_cui in snomed.get_child_cuis(parent_cui)\n",
    "}.union(parent_cuis)\n",
    "len(cuis_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_of_interest_df = snomed.synonyms_df[\n",
    "    snomed.synonyms_df[\"cui\"].isin(cuis_of_interest)\n",
    "]\n",
    "len(synonyms_of_interest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_synonyms(\n",
    "    missing_cui_and_synonyms: List[Tuple[str, str]], synonyms_df\n",
    ") -> None:\n",
    "    missing_synonyms_df = pd.DataFrame.from_records(\n",
    "        missing_cui_and_synonyms, columns=synonyms_df.columns\n",
    "    )\n",
    "    synonyms_df = pd.concat([synonyms_df, missing_synonyms_df], ignore_index=True)\n",
    "    synonyms_df.drop_duplicates(inplace=True)\n",
    "    return synonyms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_acronyms(text):\n",
    "    split = re.split(r\" - \", text, 1)\n",
    "    if len(split) > 1 and split[0].strip().isupper() and split[0].strip().isalpha():\n",
    "        return split[0].strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "extract_acronyms(\"AKI - acute kidney injury\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_and_acronyms = set()\n",
    "for _, row in tqdm(\n",
    "    synonyms_of_interest_df.iterrows(), total=len(synonyms_of_interest_df)\n",
    "):\n",
    "    acronym = extract_acronyms(row[\"name\"])\n",
    "    if acronym and len(acronym) >= 3:\n",
    "        cui_and_acronyms.add((row[\"cui\"], acronym))\n",
    "synonyms_of_interest_df = add_missing_synonyms(\n",
    "    list(cui_and_acronyms), synonyms_of_interest_df\n",
    ")\n",
    "[\n",
    "    (snomed.get_preferred_term(cui), acronym)\n",
    "    for cui, acronym in list(cui_and_acronyms)[:10]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_and_missing_synonyms = [\n",
    "    (\"384760004\", \"FEN\"),\n",
    "    # (\"365870005\", \"Code Status\"),\n",
    "    # (\"365870005\", \"Code\"),\n",
    "    (\"73211009\", \"Diabetes\"),\n",
    "    (\"73211009\", \"DM\"),  # Acryonym but shorter than 2 characters\n",
    "    (\"44054006\", \"DM2\"),\n",
    "    (\"169443000\", \"PPX\"),\n",
    "    # (\"432138007\", \"Communication\"),\n",
    "    # (\"432138007\", \"Comm\"),\n",
    "    # (\"726711005\", \"Dispo\"),\n",
    "    (\"74474003\", \"GI Bleed\"),\n",
    "    (\"160931000119108\", \"transaminitis\"),\n",
    "    (\"49436004\", \"Afib\"),\n",
    "    (\"19943007\", \"Cirrhosis\"),\n",
    "    (\"74474003\", \"GIB\"),\n",
    "    # (\"386661006\", \"Fevers\"),\n",
    "    # (\"91175000\", \"Seizures\"),\n",
    "    # (\"311788003\", \"Access\"),\n",
    "    # (\"251149006\", \"Rhythm\"),\n",
    "    # (\"739122008\", \"Pump\"),\n",
    "]\n",
    "synonyms_of_interest_df = add_missing_synonyms(\n",
    "    cui_and_missing_synonyms, synonyms_of_interest_df\n",
    ")\n",
    "[(snomed.get_preferred_term(cui), synonym) for cui, synonym in cui_and_missing_synonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_spacy = English().tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_matcher = PhraseMatcher(tokenizer_spacy.vocab, \"LOWER\")\n",
    "for cui, group_df in tqdm(synonyms_of_interest_df.groupby(\"cui\")):\n",
    "    snomed_matcher.add(cui, list(tokenizer_spacy.pipe(group_df[\"name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_keep_longest(spans):\n",
    "    sorted_spans = sorted(\n",
    "        spans, key=lambda span: (span.start, -span.end, -len(span.text))\n",
    "    )\n",
    "    filtered_spans = []\n",
    "    previous_end = -1\n",
    "    longest_span = None\n",
    "\n",
    "    for span in sorted_spans:\n",
    "        if span.start >= previous_end:\n",
    "            if longest_span:\n",
    "                filtered_spans.append(longest_span)\n",
    "            longest_span = span\n",
    "            previous_end = span.end\n",
    "        elif span.end > previous_end and len(span) > len(longest_span):\n",
    "            longest_span = span\n",
    "            previous_end = span.end\n",
    "\n",
    "    if longest_span:\n",
    "        filtered_spans.append(longest_span)\n",
    "\n",
    "    return filtered_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_diagnosis_cuis = []\n",
    "\n",
    "# for title_to_body in dataset_title_to_body[:1000]:\n",
    "#     doc_diagnosis_cuis = []\n",
    "#     for line in re.split(\"[\\n,]\", title_to_body.get(\"Discharge Diagnosis\", \"\")):\n",
    "#         matches = filter_and_keep_longest(snomed_matcher(tokenizer_spacy(line), as_spans=True))\n",
    "#         if matches:\n",
    "#             doc_diagnosis_cuis.append(matches[0].label_)\n",
    "#     dataset_diagnosis_cuis.append(doc_diagnosis_cuis)\n",
    "# print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_matcher(tokenizer_spacy(\"bradycardia/RHYTHM\"), as_spans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class PRSBGuidelines(BaseModel):\n",
    "    test: str = Field(description=\"test\")\n",
    "\n",
    "\n",
    "print(PRSBGuidelines.schema_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "num_paras = 0\n",
    "misses = []\n",
    "heading_splitter = \"[:-]\"\n",
    "for record_title_to_body in dataset_title_to_body:\n",
    "    bhc = record_title_to_body.get(\"Brief Hospital Course\", \"\")\n",
    "    bhc_paragraphs = bhc.split(\"\n",
    "\n",
    "\")\n",
    "    if len(bhc_paragraph) < 2:\n",
    "        wrong_format = 0\n",
    "    first_paragraph_line = \n",
    "    if re.splitbhc_paragraphs[0].split(\"\n",
    "\", 1)[0].splitlower().startswith(\"brief hospital course\"):\n",
    "    for bhc_paragraph in bhc.split(\"\n",
    "\n",
    "\")[1:]:\n",
    "        heading = re.split(\"[:-]\", bhc_paragraph, 1)[0]\n",
    "        # if any(skip_heading in heading.lower() for skip_heading in (\"code\", \"fen\", \"access\", \"htn\")):\n",
    "        #     continue\n",
    "        matches = filter_and_keep_longest(snomed_matcher(tokenizer_spacy(heading), as_spans=True))\n",
    "        if matches:\n",
    "            count += 1\n",
    "        if not matches:\n",
    "            misses.append(heading.lower())\n",
    "        num_paras += 1\n",
    "count/num_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(count + 223) / num_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_paras - count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(misses).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access, rhythm, pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_title_to_body[21].get(\"Brief Hospital Course\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record_title_to_body, record_diagnosis_cuis in zip(\n",
    "    dataset_title_to_body[:10], dataset_diagnosis_cuis\n",
    "):\n",
    "    bhc = record_title_to_body.get(\"Brief Hospital Course\", \"\")\n",
    "    for bhc_paragraph in bhc.split(\"\\n\\n\")[1:]:\n",
    "        first_line = bhc_paragraph.split(\"\\n\")[0]\n",
    "        matches = filter_and_keep_longest(\n",
    "            snomed_matcher(tokenizer_spacy(first_line), as_spans=True)\n",
    "        )\n",
    "        print(first_line)\n",
    "        # print(df_p_terms.loc[matches[0].label_][\"name\"] if matches else \"None\")\n",
    "        # print()\n",
    "    print()\n",
    "    print(record_title_to_body.get(\"Discharge Diagnosis\", \"\"))\n",
    "    print(record_title_to_body.get(\"Past Medical History\", \"\"))\n",
    "    # print([df_p_terms.loc[cui][\"name\"] for cui in record_diagnosis_cuis])\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(\n",
    "    df_p_terms.loc[span.label_][\"description_type_ids\"]\n",
    "    for span in tqdm(diagnosis_spans)\n",
    ").most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "keep_sentences = []\n",
    "chunks = [\n",
    "    sentence.replace(\"\\n\", \" \")\n",
    "    for note in dataset[0].physician_notes\n",
    "    for chunk in note.text.split(\"\\n\\n\")\n",
    "    for sentence in re.split(\"(?<=\\\\.) |\\n(?![a-z])\", chunk)\n",
    "]\n",
    "chunks = list(dict.fromkeys(chunks))\n",
    "for chunk in chunks:\n",
    "    doc = tokenizer_spacy(chunk)\n",
    "    matches = snomed_matcher(doc)\n",
    "    if matches:\n",
    "        keep_sentences.append(chunk)\n",
    "        # for match in matches:\n",
    "        #     print(doc[match[1]:match[2]])\n",
    "        #     print(\"*\" * 80)\n",
    "count, len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0].physician_notes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for chunk in tqdm(chunks):\n",
    "    matches = cat(chunk)\n",
    "    if matches:\n",
    "        count += 1\n",
    "count, len(chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
