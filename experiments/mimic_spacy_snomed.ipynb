{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from discharge_summaries.preprocessing.preprocess_snomed import Snomed\n",
    "from discharge_summaries.schemas.mimic import Record\n",
    "from medcat.cat import CAT\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "TRAINING_DATASET_PATH = DATA_DIR / \"train.pkl\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "RANDOM_SEED = 23\n",
    "SNOMED_DIR = (\n",
    "            Path.cwd().parent / \"data\" / \"SnomedCT_InternationalRF2_PRODUCTION_20230731T120000Z\" / \"Snapshot\"/ \"Terminology\"\n",
    "        )\n",
    "\n",
    "description_file = SNOMED_DIR / \"sct2_Description_Snapshot-en_INT_20230731.txt\"\n",
    "relation_file = SNOMED_DIR / \"sct2_Relationship_Snapshot_INT_20230731.txt\"\n",
    "\n",
    "SPACY_MODEL = \"en_core_md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_DATASET_PATH, \"rb\") as in_file:\n",
    "    dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "dataset = dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = Counter(\n",
    "    title\n",
    "    for record in tqdm(dataset)\n",
    "    for title in re.findall(\n",
    "        \"(?<=\\n\\n)[a-zA-Z ]*?(?=:.*?\\n)\", record.discharge_summary.text\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_titles = [\n",
    "    title for title, count in titles.most_common() if count > len(dataset) * 0.95\n",
    "]\n",
    "common_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_title_to_body = []\n",
    "for record in tqdm(dataset):\n",
    "    title_to_body = {}\n",
    "    for section in re.split(\n",
    "        f\"\\n\\n(?=(?:{'|'.join(common_titles)}):.*?\\n)\", record.discharge_summary.text\n",
    "    ):\n",
    "        title_and_body = section.split(\":\", maxsplit=1)\n",
    "        title_to_body[title_and_body[0]] = title_and_body[1].strip()\n",
    "    dataset_title_to_body.append(title_to_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed = Snomed(description_file, relation_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_cuis = [\n",
    "    \"404684003\", \n",
    "    '118956008', \n",
    "    \"384760004\", \n",
    "    \"365870005\", \n",
    "    \"169443000\",\n",
    "]\n",
    "[snomed.get_preferred_term(cui) for cui in parent_cuis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_and_missing_synonyms = [\n",
    "    (\"38341003\", \"HTN\"),\n",
    "    (\"384760004\", \"FEN\"),\n",
    "    (\"53741008\", \"CAD\"),\n",
    "    (\"169443000\", \"PPX\"),\n",
    "    (\"365870005\", \"Code Status\"),\n",
    "    (\"365870005\", \"Code\"),\n",
    "    (\"73211009\", \"Diabetes\"),\n",
    "    (\"73211009\", \"DM\"),\n",
    "    (\"44054006\", \"DM2\"),\n",
    "]\n",
    "[(snomed.get_preferred_term(cui), synonym) for cui, synonym in cui_and_missing_synonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_synonyms_df = pd.DataFrame.from_records(cui_and_missing_synonyms, columns=snomed.synonyms_df.columns)\n",
    "snomed.synonyms_df = pd.concat([snomed.synonyms_df, missing_synonyms_df], ignore_index=True)\n",
    "snomed.synonyms_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_of_interest = snomed.synonyms_df[snomed.synonyms_df[\"cui\"].isin(cuis_of_interest)]\n",
    "len(synonyms_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis_of_interest = {\n",
    "    child_cui\n",
    "    for parent_cui in parent_cuis\n",
    "    for child_cui in snomed.get_child_cuis(parent_cui)\n",
    "}\n",
    "len(cuis_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_spacy = English().tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_matcher = PhraseMatcher(tokenizer_spacy.vocab, \"LOWER\")\n",
    "for cui, group_df in tqdm(synonyms_of_interest.groupby(\"cui\")):\n",
    "    snomed_matcher.add(cui, list(tokenizer_spacy.pipe(group_df[\"name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_keep_longest(spans):\n",
    "    sorted_spans = sorted(spans, key=lambda span: (span.start, -span.end, -len(span.text)))\n",
    "    filtered_spans = []\n",
    "    previous_end = -1\n",
    "    longest_span = None\n",
    "\n",
    "    for span in sorted_spans:\n",
    "        if span.start >= previous_end:\n",
    "            if longest_span:\n",
    "                filtered_spans.append(longest_span)\n",
    "            longest_span = span\n",
    "            previous_end = span.end\n",
    "        elif span.end > previous_end and len(span) > len(longest_span):\n",
    "            longest_span = span\n",
    "            previous_end = span.end\n",
    "\n",
    "    if longest_span:\n",
    "        filtered_spans.append(longest_span)\n",
    "\n",
    "    return filtered_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_diagnosis_cuis = []\n",
    "\n",
    "for title_to_body in dataset_title_to_body[:1000]:\n",
    "    doc_diagnosis_cuis = []\n",
    "    for line in re.split(\"[\\n,]\", title_to_body.get(\"Discharge Diagnosis\", \"\")):\n",
    "        matches = filter_and_keep_longest(snomed_matcher(tokenizer_spacy(line), as_spans=True))\n",
    "        if matches:\n",
    "            doc_diagnosis_cuis.append(matches[0].label_)\n",
    "    dataset_diagnosis_cuis.append(doc_diagnosis_cuis)\n",
    "    # print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "num_paras = 0\n",
    "misses = []\n",
    "for record_title_to_body in dataset_title_to_body:\n",
    "    bhc = record_title_to_body.get(\"Brief Hospital Course\", \"\")\n",
    "    for bhc_paragraph in bhc.split(\"\\n\\n\")[1:]:\n",
    "        heading = re.split(\"[:-]\", bhc_paragraph, 1)[0]\n",
    "        # if any(skip_heading in heading.lower() for skip_heading in (\"code\", \"fen\", \"access\", \"htn\")):\n",
    "        #     continue\n",
    "        matches = filter_and_keep_longest(snomed_matcher(tokenizer_spacy(heading), as_spans=True))\n",
    "        if matches:\n",
    "            count += 1\n",
    "        if not matches:\n",
    "            misses.append(heading.lower())\n",
    "        num_paras += 1\n",
    "count/num_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access, rhythm, pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_matcher(tokenizer_spacy(\"fen\"), as_spans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer_spacy(\"fen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(misses).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_title_to_body[21].get(\"Brief Hospital Course\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record_title_to_body, record_diagnosis_cuis in zip(dataset_title_to_body[:10], dataset_diagnosis_cuis):\n",
    "    bhc = record_title_to_body.get(\"Brief Hospital Course\", \"\")\n",
    "    for bhc_paragraph in bhc.split(\"\\n\\n\")[1:]:\n",
    "        first_line = bhc_paragraph.split(\"\\n\")[0]\n",
    "        matches = filter_and_keep_longest(snomed_matcher(tokenizer_spacy(first_line), as_spans=True))\n",
    "        print(first_line)\n",
    "        # print(df_p_terms.loc[matches[0].label_][\"name\"] if matches else \"None\")\n",
    "        # print()\n",
    "    print()\n",
    "    print(record_title_to_body.get(\"Discharge Diagnosis\", \"\"))\n",
    "    print(record_title_to_body.get(\"Past Medical History\", \"\"))\n",
    "    # print([df_p_terms.loc[cui][\"name\"] for cui in record_diagnosis_cuis])\n",
    "    print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df_p_terms.loc[span.label_]['description_type_ids'] for span in tqdm(diagnosis_spans)).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "keep_sentences = []\n",
    "chunks = [sentence.replace(\"\\n\", \" \") for note in dataset[0].physician_notes for chunk in note.text.split(\"\\n\\n\") for sentence in re.split(\"(?<=\\.) |\\n(?![a-z])\", chunk)]\n",
    "chunks = list(dict.fromkeys(chunks))\n",
    "for chunk in chunks:\n",
    "    doc = tokenizer_spacy(chunk)\n",
    "    matches = snomed_matcher(doc)\n",
    "    if matches:\n",
    "        keep_sentences.append(chunk)\n",
    "        # for match in matches:\n",
    "        #     print(doc[match[1]:match[2]])\n",
    "        #     print(\"*\" * 80)\n",
    "count, len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0].physician_notes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for chunk in tqdm(chunks):\n",
    "    matches = cat(chunk)\n",
    "    if matches:\n",
    "        count += 1\n",
    "count, len(chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
