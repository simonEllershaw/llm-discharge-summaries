{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from medcat.cat import CAT\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.schemas.mimic import Record\n",
    "from discharge_summaries.schemas.span import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "TRAINING_DATASET_PATH = DATA_DIR / \"train.pkl\"\n",
    "TRAINING_ANNO_DATASET_PATH = DATA_DIR / \"train_anno.pkl\"\n",
    "DATASET_NOTE_CUI_CACHE_PATH = DATA_DIR / \"dataset_note_cui_cache.json\"\n",
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5.zip\"\n",
    ")\n",
    "RANDOM_SEED = 23\n",
    "LOG_FILE = \"./medcat.log\"\n",
    "DIRECT_LABEL = \"DIRECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_DATASET_PATH, \"rb\") as in_file:\n",
    "    dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "dataset = dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CAT.load_model_pack(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.pipe.spacy_nlp.disable_pipes([\"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cuis_from_text(text: str, cat: CAT):\n",
    "    text_ents = cat(text).ents if text else ()\n",
    "    return {ent._.cui for ent in text_ents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_type_names = {\n",
    "    \"disorder\",\n",
    "    \"finding\",\n",
    "    \"morphologic abnormality\",\n",
    "    \"organism\",\n",
    "    \"physical object\",\n",
    "    \"clinical drug\",\n",
    "    \"medicinal product form\",\n",
    "    \"procedure\",\n",
    "    \"product\",\n",
    "}\n",
    "\n",
    "type_name_to_id = {\n",
    "    name: type_id for type_id, name in cat.cdb.addl_info[\"type_id2name\"].items()\n",
    "}\n",
    "\n",
    "type_ids_filter = [type_name_to_id[type_name] for type_name in filter_type_names]\n",
    "\n",
    "full_cui_filters = {\n",
    "    cui\n",
    "    for type_ids in type_ids_filter\n",
    "    for cui in cat.cdb.addl_info[\"type_id2cuis\"][type_ids]\n",
    "}\n",
    "cat.cdb.config.linking[\"filters\"][\"cuis\"] = full_cui_filters\n",
    "len(full_cui_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_annotations = []\n",
    "spacy_pipeline = cat.pipe.spacy_nlp\n",
    "for doc in tqdm(dataset):\n",
    "    doc_annotations = []\n",
    "\n",
    "    doc_headings = [\n",
    "        para.heading for para in doc.discharge_summary.bhc_paragraphs if para.heading\n",
    "    ]\n",
    "    matcher = PhraseMatcher(spacy_pipeline.vocab, attr=\"LOWER\")\n",
    "    matcher.add(\"DIRECT\", list(spacy_pipeline.tokenizer.pipe(doc_headings)))\n",
    "\n",
    "    cat.cdb.config.linking[\"filters\"][\"cuis\"] = full_cui_filters\n",
    "    para_cuis = {ent._.cui for ent in cat(\"\\n\\n\".join(doc_headings)).ents}\n",
    "\n",
    "    cat.cdb.config.linking[\"filters\"][\"cuis\"] = para_cuis\n",
    "    for idx, note in enumerate(doc.physician_notes):\n",
    "        note_spacy = cat(note.text)\n",
    "        note_annotations = [\n",
    "            Span(start=ent.start_char, end=ent.end_char, text=ent.text, label=ent._.cui)\n",
    "            for ent in cat(note.text).ents\n",
    "        ]\n",
    "        cui_anno_start_ends = {(anno.start, anno.end) for anno in note_annotations}\n",
    "        for match in matcher(spacy_pipeline.tokenizer(note.text), as_spans=True):\n",
    "            if (match.start_char, match.end_char) not in cui_anno_start_ends:\n",
    "                note_annotations.append(\n",
    "                    Span(\n",
    "                        start=match.start_char,\n",
    "                        end=match.end_char,\n",
    "                        text=match.text,\n",
    "                        label=DIRECT_LABEL,\n",
    "                    )\n",
    "                )\n",
    "        doc_annotations.append(note_annotations)\n",
    "    dataset_annotations.append(doc_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(spacy_pipeline.vocab, attr=\"LOWER\")\n",
    "matcher.add(\"DIRECT\", list(spacy_pipeline.tokenizer.pipe([\"apple\"])))\n",
    "matcher(spacy_pipeline.tokenizer(\"banna apple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_annotations = {\n",
    "    anno.text for note_annos in dataset_annotations[0] for anno in note_annos\n",
    "}\n",
    "headings = sorted(\n",
    "    [\n",
    "        para.heading\n",
    "        for para in dataset[0].discharge_summary.bhc_paragraphs\n",
    "        if para.heading\n",
    "    ]\n",
    ")\n",
    "text_annotations, headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_headings = 0\n",
    "num_matches = 0\n",
    "cui_hits = []\n",
    "partial_cui_hit = []\n",
    "strict_match = []\n",
    "no_match = []\n",
    "cat.cdb.config.linking[\"filters\"][\"cuis\"] = full_cui_filters\n",
    "\n",
    "for doc, docs_annotations in tqdm(zip(dataset, dataset_annotations)):\n",
    "    doc_anno_cuis = {\n",
    "        anno.label\n",
    "        for note_annotations in docs_annotations\n",
    "        for anno in note_annotations\n",
    "        if anno.label != \"DIRECT\"\n",
    "    }\n",
    "    doc_anno_direct_text = {\n",
    "        anno.text.lower()\n",
    "        for note_annotations in docs_annotations\n",
    "        for anno in note_annotations\n",
    "        if anno.label == \"DIRECT\"\n",
    "    }\n",
    "\n",
    "    for para in doc.discharge_summary.bhc_paragraphs:\n",
    "        if not para.heading:\n",
    "            continue\n",
    "        num_headings += 1\n",
    "        para_cuis = {ent._.cui for ent in cat(para.heading).ents}\n",
    "        if para_cuis and para_cuis.issubset(doc_anno_cuis):\n",
    "            # print(para_cuis, doc_anno_cuis)\n",
    "            cui_hits.append(para.heading)\n",
    "        elif para_cuis.intersection(doc_anno_cuis) != set():\n",
    "            partial_cui_hit.append(para.heading)\n",
    "        elif para.heading.lower() in doc_anno_direct_text:\n",
    "            strict_match.append(para.heading)\n",
    "        else:\n",
    "            no_match.append(para.heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hit_rate = (\n",
    "    len(cui_hits) + len(partial_cui_hit) + len(strict_match)\n",
    ") / num_headings\n",
    "cui_hit_rate = len(cui_hits) / num_headings\n",
    "partial_cui_hit_rate = len(partial_cui_hit) / num_headings\n",
    "strict_match_rate = len(strict_match) / num_headings\n",
    "no_match_rate = len(no_match) / num_headings\n",
    "\n",
    "total_hit_rate, cui_hit_rate, partial_cui_hit_rate, strict_match_rate, no_match_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(no_match).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_ANNO_DATASET_PATH, \"wb\") as out_file:\n",
    "    pickle.dump(dataset_annotations, out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
