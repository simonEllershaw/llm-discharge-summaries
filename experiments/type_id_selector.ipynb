{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from medcat.cat import CAT\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.schemas.mimic import Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "GT_DATA_PATH = DATA_DIR / \"train.pkl\"\n",
    "\n",
    "MODEL_PATH = Path.cwd().parent / \"models\" / \"umls_sm_pt2ch_533bab5115c6c2d6.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CAT.load_model_pack(MODEL_PATH)\n",
    "cat.pipe.force_remove(\"Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GT_DATA_PATH, \"rb\") as in_file:\n",
    "    train_dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_headings = [\n",
    "    para.heading\n",
    "    for sample in train_dataset\n",
    "    for para in sample.discharge_summary.bhc_paragraphs\n",
    "    if para.heading\n",
    "]\n",
    "len(train_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for heading in train_headings[:100]:\n",
    "    print(heading)\n",
    "    for entity in cat.get_entities(heading)[\"entities\"].values():\n",
    "        print(entity[\"pretty_name\"], entity[\"types\"], entity[\"type_ids\"])\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type IDS for each heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_type_ids(text: str, cat: CAT) -> set[str]:\n",
    "    annotated_text = cat(text)\n",
    "    return (\n",
    "        {\n",
    "            type_id\n",
    "            for ent in annotated_text.ents\n",
    "            for type_id in cat.cdb.cui2type_ids.get(ent._.cui, [])\n",
    "        }\n",
    "        if annotated_text\n",
    "        else set()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_heading_type_ids = [\n",
    "    extract_type_ids(heading, cat) for heading in tqdm(train_headings)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hits = sum(1 for type_id in train_heading_type_ids if type_id)\n",
    "(num_hits) / len(train_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_id_frequency = Counter(\n",
    "    type_id for type_ids in train_heading_type_ids for type_id in type_ids\n",
    ")\n",
    "type_id_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_proportion_labelled = []\n",
    "for k in range(1, len(type_id_frequency) + 1):\n",
    "    chosen_type_ids = {type_id for type_id, _ in type_id_frequency.most_common(k)}\n",
    "    num_headings_labelled = sum(\n",
    "        [\n",
    "            1\n",
    "            for heading_ids in train_heading_type_ids\n",
    "            if heading_ids.intersection(chosen_type_ids)\n",
    "        ]\n",
    "    )\n",
    "    k_proportion_labelled.append(num_headings_labelled / len(train_headings))\n",
    "k_proportion_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(chosen_type_ids) + 1), k_proportion_labelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type_ids chosen as disorder + virus and bacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_type_ids = set(\n",
    "    [\n",
    "        \"T020\",\n",
    "        \"T190\",\n",
    "        \"T049\",\n",
    "        \"T019\",\n",
    "        \"T047\",\n",
    "        \"T050\",\n",
    "        \"T033\",\n",
    "        \"T037\",\n",
    "        \"T048\",\n",
    "        \"T191\",\n",
    "        \"T046\",\n",
    "        \"T184\",\n",
    "    ]\n",
    "    + [\"T005\", \"T007\"]\n",
    ")\n",
    "num_headings_labelled = sum(\n",
    "    [\n",
    "        1\n",
    "        for heading_ids in train_heading_type_ids\n",
    "        if heading_ids.intersection(chosen_type_ids)\n",
    "    ]\n",
    ")\n",
    "num_headings_labelled / len(train_headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at which headings were totally missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_headings = [\n",
    "    heading.lower()\n",
    "    for heading, type_ids in zip(train_headings, train_heading_type_ids)\n",
    "    if not type_ids\n",
    "]\n",
    "formatted_misses = []\n",
    "for heading in missed_headings:\n",
    "    split_space = heading.split(\" \", maxsplit=1)\n",
    "    if len(split_space) > 1:\n",
    "        formatted_misses.append(split_space[1].strip())\n",
    "    else:\n",
    "        formatted_misses.append(heading[1:])\n",
    "Counter(formatted_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_headings_reduced = [\n",
    "    para.heading\n",
    "    for sample in train_dataset\n",
    "    for para in sample.discharge_summary.bhc_paragraphs\n",
    "    if para.heading\n",
    "    and not re.search(r\"code|access|communication|fen\", para.heading.lower())\n",
    "]\n",
    "len(train_headings_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_heading_type_ids_reduced = [\n",
    "    extract_type_ids(heading, cat) for heading in tqdm(train_headings_reduced)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hits = sum(1 for type_id in train_heading_type_ids_reduced if type_id)\n",
    "num_hits / len(train_headings_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected type ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_headings_labelled = sum(\n",
    "    [\n",
    "        1\n",
    "        for heading_ids in train_heading_type_ids_reduced\n",
    "        if heading_ids.intersection(chosen_type_ids)\n",
    "    ]\n",
    ")\n",
    "num_headings_labelled / len(train_headings_reduced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
