{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from discharge_summaries.preprocessing.preprocess_snomed import Snomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "SNOMED_DIR = (\n",
    "    Path.cwd().parent\n",
    "    / \"data\"\n",
    "    / \"SnomedCT_InternationalRF2_PRODUCTION_20230731T120000Z\"\n",
    "    / \"Snapshot\"\n",
    "    / \"Terminology\"\n",
    ")\n",
    "description_file = SNOMED_DIR / \"sct2_Description_Snapshot-en_INT_20230731.txt\"\n",
    "relation_file = SNOMED_DIR / \"sct2_Relationship_Snapshot_INT_20230731.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed = Snomed.load_from_raw_snomed_files(description_file, relation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician_notes_df = pd.read_csv(MIMIC_III_DIR / \"physician_notes.csv\")\n",
    "procedures_df = pd.read_csv(MIMIC_III_DIR / \"PROCEDUREEVENTS_MV.csv\")\n",
    "items_df = pd.read_csv(MIMIC_III_DIR / \"D_ITEMS.csv\", usecols=[\"ITEMID\", \"LABEL\"])\n",
    "procedures_df = pd.merge(\n",
    "    procedures_df,\n",
    "    items_df[[\"ITEMID\", \"LABEL\"]],\n",
    "    on=\"ITEMID\",\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hadm_id = list(physician_notes_df[\"HADM_ID\"].unique())[1]\n",
    "sample_hadm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_physician_notes = physician_notes_df[\n",
    "    physician_notes_df[\"HADM_ID\"] == sample_hadm_id\n",
    "]\n",
    "sample_physician_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_procedures = procedures_df[procedures_df[\"HADM_ID\"] == sample_hadm_id]\n",
    "sample_procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_cuis = snomed.get_child_cuis(\"71388002\").union(\n",
    "    snomed.get_child_cuis(\"129125009\")\n",
    ")\n",
    "len(procedure_cuis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tokenizer_spacy = English().tokenizer\n",
    "snomed_matcher = PhraseMatcher(tokenizer_spacy.vocab, \"LOWER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_synonyms = snomed.synonyms_df.groupby(\"cui\")\n",
    "for cui in tqdm(procedure_cuis):\n",
    "    snomed_matcher.add(\n",
    "        cui, list(tokenizer_spacy.pipe(grouped_synonyms.get_group(cui)[\"name\"].values))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = tokenizer_spacy(\"operation\")\n",
    "matches = snomed_matcher(doc)\n",
    "snomed.get_preferred_term(tokenizer_spacy.vocab.strings[matches[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_sample_physician_notes = \"\\n\\n\".join(sample_physician_notes[\"TEXT\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = tokenizer_spacy(joined_sample_physician_notes)\n",
    "matches = snomed_matcher(doc)\n",
    "snomed.get_preferred_term(tokenizer_spacy.vocab.strings[matches[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_physician_notes.iloc[-1][\"TEXT\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
