{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import openpyxl\n",
    "import PyPDF2\n",
    "import tiktoken\n",
    "\n",
    "from discharge_summaries.schemas.prsb_guidelines import (\n",
    "    ArrayElement,\n",
    "    ClusterElement,\n",
    "    Element,\n",
    "    RecordElement,\n",
    "    Row,\n",
    "    Section,\n",
    "    clean_text,\n",
    "    to_camel_case,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDELINES_DIR = Path.cwd().parent / \"guidelines\"\n",
    "GUIDELINES_EXCEL_PATH = GUIDELINES_DIR / \"eDischarge-Summary-v2.1-1st-Feb-21.xlsx\"\n",
    "GUIDELINES_PYDANTIC_MODEL_PATH = (\n",
    "    GUIDELINES_DIR / \"eDischarge-Summary-v2.1-1st-Feb-21_pydantic.json\"\n",
    ")\n",
    "GUIDELINES_IMPLEMENTATION_PDF_PATH = (\n",
    "    GUIDELINES_DIR\n",
    "    / \"eDischarge-Summary-Maintenance-Release-Implementation-Guidance-Report-v2.1-23.1.19.pdf\"\n",
    ")\n",
    "TOKENIZER = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = openpyxl.load_workbook(GUIDELINES_EXCEL_PATH)[\"Sheet1\"]\n",
    "# First 4 rows are headers\n",
    "rows = list(sheet.iter_rows(values_only=True, min_row=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_rows(rows: List[Row]) -> List[Row]:\n",
    "    # This function returns the cluster rows between the cluster header\n",
    "    # e.g. medication_item_cluster and cluster tail e.g. end_of_medication_item_cluster\n",
    "    # If no cluster tail header present the end of the cluster is the final row\n",
    "    cluster_rows = []\n",
    "    if len(rows) <= 1:\n",
    "        raise ValueError(f\"Only the header of a cluster was found. {rows}\")\n",
    "    for row in rows[1:]:\n",
    "        if row.name == f\"end_of_{rows[0].name}\":\n",
    "            break\n",
    "        cluster_rows.append(row)\n",
    "\n",
    "    return cluster_rows\n",
    "\n",
    "\n",
    "def rows_to_elements(rows: List[Row]) -> List[Element]:\n",
    "    elements = []\n",
    "    row_idx = 0\n",
    "    rows = [row for row in rows if row.do_not_use is False]\n",
    "    while row_idx < len(rows):\n",
    "        row = rows[row_idx]\n",
    "        if \"record entry\" in row.description:\n",
    "            element = RecordElement(\n",
    "                name=row.name,\n",
    "                description=row.description,\n",
    "                items=rows_to_elements(rows[row_idx + 1 :]),\n",
    "            )\n",
    "            # Record entries are whole section objects\n",
    "            row_idx = len(rows)\n",
    "        elif row.name.endswith(\"item_entry\"):\n",
    "            cluster_rows = get_cluster_rows(rows[row_idx + 1 :])\n",
    "            element = RecordElement(\n",
    "                name=row.name,\n",
    "                description=row.description,\n",
    "                items=rows_to_elements(cluster_rows),\n",
    "            )\n",
    "            # Item entries have title, cluster head and tail rows\n",
    "            row_idx += len(cluster_rows) + 3\n",
    "        elif row.cardinality.startswith(\"0 to many\"):\n",
    "            element = ArrayElement(\n",
    "                name=row.name,\n",
    "                description=row.description,\n",
    "            )\n",
    "            row_idx += 1\n",
    "        elif row.name.endswith(\"cluster\"):\n",
    "            cluster_rows = get_cluster_rows(rows[row_idx:])\n",
    "            element = ClusterElement(\n",
    "                name=row.name,\n",
    "                description=row.description,\n",
    "                elements=rows_to_elements(cluster_rows),\n",
    "            )\n",
    "            # Clusters have head and tail rows\n",
    "            row_idx += len(cluster_rows) + 2\n",
    "        else:\n",
    "            element = Element(\n",
    "                name=row.name,\n",
    "                description=row.description,\n",
    "            )\n",
    "            row_idx += 1\n",
    "        elements.append(element)\n",
    "    return elements\n",
    "\n",
    "\n",
    "def rows_to_section(section_rows: List[Row]) -> Section:\n",
    "    section_row = section_rows[1]\n",
    "    element_rows = section_rows[3:]\n",
    "    return Section(\n",
    "        name=section_row.name,\n",
    "        description=section_row.description,\n",
    "        elements=rows_to_elements(element_rows),\n",
    "    )\n",
    "\n",
    "\n",
    "def rows_to_sections(rows: List[List[str]]) -> List[Section]:\n",
    "    section_models = []\n",
    "    section_rows: List[Row] = []\n",
    "    for row in rows:\n",
    "        if all(element is None for element in row):\n",
    "            section_models.append(rows_to_section(section_rows))\n",
    "            section_rows = []\n",
    "        else:\n",
    "            section_rows.append(Row.from_record(row))\n",
    "    section_models.append(rows_to_section(section_rows))\n",
    "    return [\n",
    "        section_model for section_model in section_models if section_model is not None\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = rows_to_sections(rows)\n",
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema_dict: Dict = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        k: v for section in sections for k, v in section.to_json_schema_dict().items()\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TOKENIZER.encode(json.dumps(json_schema_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfReader(GUIDELINES_IMPLEMENTATION_PDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [line for page in reader.pages for line in page.extract_text().split(\"\\n\")]\n",
    "# Remove pdf footers\n",
    "text = [\n",
    "    re.sub(\n",
    "        (\n",
    "            \"(PRSB eDischarge Summary  â€“ Implementation Guidance  V2.1)|(January 2019 \"\n",
    "            r\" Page \\d+  )|(January 2019  Page \\d+  )\"\n",
    "        ),\n",
    "        \"\",\n",
    "        line,\n",
    "    ).strip()\n",
    "    for line in text\n",
    "]\n",
    "# Tody up parsed text\n",
    "text = [re.sub(\" {2,}\", \" \", line) for line in text]\n",
    "text = [re.sub(\"reco rd\", \"record\", line) for line in text]\n",
    "text = [line for line in text if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_heading_idx = len(text)\n",
    "heading_to_text = {}\n",
    "for heading_idx, line in enumerate(reversed(text)):\n",
    "    if re.match(r\"^\\d+\\.\\d+ [A-Za-z ]+$\", line):\n",
    "        section_text = \"\\n\".join(text[len(text) - heading_idx : last_heading_idx])\n",
    "        section_text = re.sub(r\"\\d+.\\d+.\\d+ \", \"\", section_text)\n",
    "        section_text = re.sub(\"\\n(?=[a-z])\", \" \", section_text)\n",
    "        section_text = clean_text(section_text)\n",
    "        heading = to_camel_case(re.sub(r\"\\d+.\\d+ \", \"\", line))\n",
    "\n",
    "        heading_to_text[heading] = section_text\n",
    "        last_heading_idx = len(text) - heading_idx - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for property_heading, property_body in json_schema_dict[\"properties\"].items():\n",
    "    if property_heading in heading_to_text:\n",
    "        property_body[\"description\"] += f\"\\n{heading_to_text[property_heading]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TOKENIZER.encode(json.dumps(json_schema_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDELINES_PYDANTIC_MODEL_PATH.write_text(json.dumps(json_schema_dict, indent=4))\n",
    "GUIDELINES_PYDANTIC_MODEL_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
