{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://htmlpreview.github.io/?https://github.com/CogStack/MedCATtutorials/blob/main/notebooks/specialised/Preprocessing_SNOMED_CT.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from medcat.utils.preprocess_snomed import Snomed\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.schemas.mimic import Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOMED_PATH = (\n",
    "    Path.cwd().parent / \"data\" / \"SnomedCT_InternationalRF2_PRODUCTION_20230731T120000Z\"\n",
    ")\n",
    "MODEL_DIR = Path.cwd().parent / \"models\"\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "GT_DATA_PATH = DATA_DIR / \"train.pkl\"\n",
    "\n",
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GT_DATA_PATH, \"rb\") as in_file:\n",
    "    gt_dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "len(gt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing SNOMED CT for MedCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sowmed = Snomed(str(SNOMED_PATH))\n",
    "sowmed.uk_ext = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sowmed.to_concept_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description_type_ids\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_type_names = {\n",
    "    \"disorder\",\n",
    "    \"finding\",\n",
    "    \"morphologic abnormality\",\n",
    "    \"organism\",\n",
    "    \"physical object\",\n",
    "    \"clinical drug\",\n",
    "    \"medicinal product form\",\n",
    "    \"procedure\",\n",
    "    \"product\",\n",
    "}\n",
    "assert all(name in df[\"description_type_ids\"].unique() for name in filter_type_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"description_type_ids\"].isin(filter_type_names)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset = df[df['description_type_ids'].isin(['finding', 'disorder'])]\n",
    "df_subset = df[df[\"name_status\"] == \"A\"]\n",
    "len(df_subset), len(df_subset[\"cui\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = English().tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(tokenizer.vocab, \"LOWER\")\n",
    "for cui, group_df in tqdm(df_subset.groupby(\"cui\")):\n",
    "    matcher.add(cui, list(tokenizer.pipe(group_df[\"name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(tokenizer(\"code status\"), as_spans=True)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(tokenizer(\"this patient had a Cardiac infarction\"), as_spans=True)\n",
    "matches[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "TRAINING_DATASET_PATH = DATA_DIR / \"train.pkl\"\n",
    "DATASET_NOTE_CUI_CACHE_PATH = DATA_DIR / \"dataset_note_cui_cache.json\"\n",
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5.zip\"\n",
    ")\n",
    "RANDOM_SEED = 23\n",
    "LOG_FILE = \"./medcat.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_DATASET_PATH, \"rb\") as in_file:\n",
    "    dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "dataset = dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_matches = matcher(tokenizer(\"heart attack\"), as_spans=True)\n",
    "para_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(\n",
    "    len(\n",
    "        \"/n/n\".join(\n",
    "            note.text for note in doc.physician_notes if note.category in {\"Physician \"}\n",
    "        )\n",
    "    )\n",
    "    for doc in dataset\n",
    ") / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_headings = 0\n",
    "num_matches = 0\n",
    "cui_hits = []\n",
    "partial_cui_hit = []\n",
    "strict_match = []\n",
    "no_match = []\n",
    "for doc in tqdm(dataset[:10]):\n",
    "    # para_headings = [para.heading for para in doc.discharge_summary.bhc_paragraphs if para.heading]\n",
    "    # direct_match_ids = [f\"D-{idx}\" for idx, _ in enumerate(para_headings)]\n",
    "\n",
    "    # direct_matcher = (tokenizer.vocab, \"LOWER\")\n",
    "    # for heading, idx in zip(para_headings, direct_match_ids):\n",
    "    #     direct_matcher.add(idx, [tokenizer(heading)])\n",
    "\n",
    "    doc_note_text = \"\\n\\n\".join(\n",
    "        note.text.lower()\n",
    "        for note in doc.physician_notes\n",
    "        if note.category in {\"Physician \"}\n",
    "    )\n",
    "    doc_note_spacy = tokenizer(doc_note_text)\n",
    "    doc_note_matches = matcher(doc_note_spacy, as_spans=True)\n",
    "    doc_note_cuis = {span.label_ for span in doc_note_matches}\n",
    "\n",
    "    for para in doc.discharge_summary.bhc_paragraphs:\n",
    "        if not para.heading:\n",
    "            continue\n",
    "        num_headings += 1\n",
    "        para_spacy = tokenizer(para.heading)\n",
    "        para_matches = matcher(para_spacy, as_spans=True)\n",
    "        para_cuis = {span.label_ for span in para_matches}\n",
    "\n",
    "        if para_cuis and para_cuis.issubset(doc_note_cuis):\n",
    "            cui_hits.append(para.heading)\n",
    "        elif para_cuis.intersection(doc_note_cuis) != set():\n",
    "            partial_cui_hit.append(para.heading)\n",
    "        elif para.heading.lower() in doc_note_text:\n",
    "            strict_match.append(para.heading)\n",
    "        else:\n",
    "            no_match.append(para.heading)\n",
    "\n",
    "        # print(\"Heading\", para.heading)\n",
    "        # print(para_cuis)\n",
    "        # for doc_note_match in doc_note_matches:\n",
    "        #     if doc_note_match.label_ in para_cuis:\n",
    "        #         print(doc_note_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hit_rate = (\n",
    "    len(cui_hits) + len(partial_cui_hit) + len(strict_match)\n",
    ") / num_headings\n",
    "cui_hit_rate = len(cui_hits) / num_headings\n",
    "partial_cui_hit_rate = len(partial_cui_hit) / num_headings\n",
    "strict_match_rate = len(strict_match) / num_headings\n",
    "no_match_rate = len(no_match) / num_headings\n",
    "\n",
    "total_hit_rate, cui_hit_rate, partial_cui_hit_rate, strict_match_rate, no_match_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(tokenizer(\"ST Elevation Myocardial Infarction\"), as_spans=True)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in matches:\n",
    "    print(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not para_cuis:\n",
    "#     not_annotated.append(para.heading)\n",
    "# elif para_cuis.issubset(doc_note_cuis):\n",
    "#     complete_match.append(para.heading)\n",
    "# elif para_cuis.intersection(doc_note_cuis):\n",
    "#     partial_match.append(para.heading)\n",
    "#     matched_cuis = para_cuis.intersection(doc_note_cuis)\n",
    "#     if matched_cuis(direct_match_ids).intersection():\n",
    "#         heading_match.append(para.heading)\n",
    "# else:\n",
    "#     no_match.append(para.heading)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
