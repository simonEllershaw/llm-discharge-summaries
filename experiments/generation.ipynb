{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from medcat.cat import CAT\n",
    "from spacy.pipeline import Sentencizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.prompts.diagnosis_summary import diagnosis_summary_prompt\n",
    "from discharge_summaries.schemas.medcat import MedCATSpan\n",
    "from discharge_summaries.schemas.mimic import Note, Record\n",
    "from discharge_summaries.schemas.output import Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "UMLS_API_KEY = os.environ.get(\"UMLS_API_KEY\")\n",
    "\n",
    "UMLS_BASE_URL = \"https://uts-ws.nlm.nih.gov/rest\"\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "DATA_PATH = DATA_DIR / \"train.pkl\"\n",
    "OUTPUT_PATH = DATA_DIR / \"output.json\"\n",
    "\n",
    "MODEL_PATH = Path.cwd().parent / \"models\" / \"umls_sm_pt2ch_533bab5115c6c2d6.zip\"\n",
    "\n",
    "OPEN_API_VERSION = \"2023-05-15\"\n",
    "DEPLOYMENT_NAME = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH, \"rb\") as in_file:\n",
    "    dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "dataset = dataset[:3]\n",
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CAT.load_model_pack(MODEL_PATH)\n",
    "type_ids_filter = [\"T047\"]\n",
    "cui_filters = {\n",
    "    cui\n",
    "    for type_ids in type_ids_filter\n",
    "    for cui in cat.cdb.addl_info[\"type_id2cuis\"][type_ids]\n",
    "}\n",
    "cat.cdb.config.linking[\"filters\"][\"cuis\"] = cui_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.pipe._nlp.add_pipe(\n",
    "    \"sentencizer\", config={\"punct_chars\": Sentencizer.default_punct_chars.append(\"\\n\")}\n",
    ")\n",
    "cat.pipe._nlp.enable_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_version=OPEN_API_VERSION,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    temperature=0,\n",
    "    request_timeout=20,\n",
    ")\n",
    "\n",
    "diagnosis_summary_chain = LLMChain(llm=model, prompt=diagnosis_summary_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_medcat_entities(text: str, cat: CAT) -> list[MedCATSpan]:\n",
    "    doc = cat(text)\n",
    "    sentences = list(doc.sents)\n",
    "    num_context_sentences = 1\n",
    "    total_context_sentences = 2 * num_context_sentences + 1\n",
    "    ents = []\n",
    "    for sent_idx, sent in enumerate(doc.sents):\n",
    "        if total_context_sentences > len(sentences):\n",
    "            context = sentences\n",
    "        if sent_idx - num_context_sentences < 0:\n",
    "            context = sentences[:total_context_sentences]\n",
    "        elif sent_idx + num_context_sentences + 1 > len(sentences):\n",
    "            context = sentences[-total_context_sentences:]\n",
    "        else:\n",
    "            context = sentences[\n",
    "                sent_idx - num_context_sentences : sent_idx + num_context_sentences + 1\n",
    "            ]\n",
    "        context_str = \" \".join([str(sent) for sent in context])\n",
    "        for ent in sent.ents:\n",
    "            ents.append(MedCATSpan.from_spacy_span(ent, cat, context=context_str))\n",
    "    return ents\n",
    "\n",
    "\n",
    "def filter_entities_by_confidence_and_affirmed_status(\n",
    "    entities: list[MedCATSpan], confidence_threshold=0.9\n",
    "):\n",
    "    return [\n",
    "        entity\n",
    "        for entity in entities\n",
    "        if entity.meta_anns.get(\"Status\", {}).get(\"value\", \"\") == \"Affirmed\"\n",
    "        and entity.meta_anns.get(\"Status\", {}).get(\"confidence\", \"\") > 0.9\n",
    "    ]\n",
    "\n",
    "\n",
    "def group_entities_by_cui(entities: list[MedCATSpan]) -> dict[str, list[MedCATSpan]]:\n",
    "    cui_to_entities: dict[str, list[MedCATSpan]] = defaultdict(list)\n",
    "    for entity in entities:\n",
    "        cui_to_entities[entity.cui].append(entity)\n",
    "    return cui_to_entities\n",
    "\n",
    "\n",
    "def string_to_word_set(string: str) -> set[str]:\n",
    "    return set(re.findall(r\"\\w+\", string.lower()))\n",
    "\n",
    "\n",
    "def de_duplicate_entities_based_on_content_overlap(\n",
    "    entities: list[MedCATSpan], threshold=0.75\n",
    ") -> list[MedCATSpan]:\n",
    "    unique_entities_and_set: list[tuple[MedCATSpan, set[str]]] = []\n",
    "\n",
    "    for entity in entities:\n",
    "        is_duplicate = False\n",
    "        entity_set = string_to_word_set(entity.context)\n",
    "        for _, unique_entity_set in unique_entities_and_set:\n",
    "            overlap = len(entity_set.intersection(unique_entity_set)) / len(\n",
    "                unique_entity_set\n",
    "            )\n",
    "            if overlap > threshold:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "\n",
    "        if not is_duplicate:\n",
    "            unique_entities_and_set.append((entity, entity_set))\n",
    "\n",
    "    return [entity for entity, _ in unique_entities_and_set]\n",
    "\n",
    "\n",
    "def remove_table_headings_entities(entities: list[MedCATSpan]) -> list[MedCATSpan]:\n",
    "    return [\n",
    "        entity\n",
    "        for entity in entities\n",
    "        if not (re.search(f\"{re.escape(entity.text)}*:*\\n\", entity.context))\n",
    "    ]\n",
    "\n",
    "\n",
    "def extract_cui_to_entities(\n",
    "    physician_notes: list[Note], cat: CAT\n",
    ") -> dict[str, list[MedCATSpan]]:\n",
    "    entities = [\n",
    "        ent\n",
    "        for note in physician_notes\n",
    "        for ent in annotate_medcat_entities(note.text, cat)\n",
    "    ]\n",
    "\n",
    "    entities = filter_entities_by_confidence_and_affirmed_status(entities)\n",
    "\n",
    "    cui_to_entities = group_entities_by_cui(entities)\n",
    "\n",
    "    cui_to_entities = {\n",
    "        cui: de_duplicate_entities_based_on_content_overlap(entities)\n",
    "        for cui, entities in cui_to_entities.items()\n",
    "    }\n",
    "\n",
    "    cui_to_entities = {\n",
    "        cui: remove_table_headings_entities(entities)\n",
    "        for cui, entities in cui_to_entities.items()\n",
    "    }\n",
    "\n",
    "    cui_to_entities = {\n",
    "        cui: entities for cui, entities in cui_to_entities.items() if len(entities) > 1\n",
    "    }\n",
    "\n",
    "    return cui_to_entities\n",
    "\n",
    "\n",
    "def cui_to_name(cui: str, cat: CAT) -> str:\n",
    "    return cat.cdb.get_name(cui)\n",
    "\n",
    "\n",
    "def cuis_to_names(cuis: list[str], cat: CAT) -> list[str]:\n",
    "    return sorted(cat.cdb.get_name(cui) for cui in cuis)\n",
    "\n",
    "\n",
    "async def async_generate_topic_paragraph(\n",
    "    diagnosis: str, ehr_extracts: list[str], llm_chain: LLMChain\n",
    ") -> Paragraph:\n",
    "    ehr_extracts_str = \"\\n\".join(ehr_extracts)\n",
    "    llm_output = await llm_chain.arun(\n",
    "        {\n",
    "            \"diagnosis\": diagnosis,\n",
    "            \"ehr_extracts\": ehr_extracts_str,\n",
    "        }\n",
    "    )\n",
    "    return Paragraph(text=llm_output, heading=diagnosis, evidence=ehr_extracts)\n",
    "\n",
    "\n",
    "async def generate_brief_hospital_course(\n",
    "    physician_notes: list[Note], cat: CAT, llm_chain: LLMChain\n",
    ") -> list[Paragraph]:\n",
    "    cui_to_entities = extract_cui_to_entities(physician_notes, cat)\n",
    "    tasks = [\n",
    "        async_generate_topic_paragraph(\n",
    "            cui_to_name(cui, cat), [entity.context for entity in entities], llm_chain\n",
    "        )\n",
    "        for cui, entities in cui_to_entities.items()\n",
    "    ]\n",
    "    bhcs = await asyncio.gather(*tasks)\n",
    "    return bhcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = [\n",
    "    # https://stackoverflow.com/questions/55409641/asyncio-run-cannot-be-called-from-a-running-event-loop-when-using-jupyter-no\n",
    "    await generate_brief_hospital_course(  # type: ignore\n",
    "        sample.physician_notes, cat, diagnosis_summary_chain\n",
    "    )\n",
    "    for sample in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with OUTPUT_PATH.open(\"w\") as fout:\n",
    "    json.dump([[para.dict() for para in bhc] for bhc in generations], fout, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMLS Matching (legacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formatted_summaries = []\n",
    "for summary in output.split(\"\\n\\n\"):\n",
    "    words = summary.split(\" \")\n",
    "    lines = [\" \".join(words[i : i + 10]) for i in range(0, len(words), 10)]\n",
    "    formatted_summaries.append(\"\\n\".join(lines))\n",
    "\n",
    "(DATA_DIR / \"test_output.txt\").write_text(\"\\n\\n\".join(formatted_summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def calc_matches_including_parents(cuis: set[str], cuis_compare: set[str], cat: CAT)->list[str]:\n",
    "    cuis_compare_parents = {parent_cui for cui in cuis_compare for parent_cui in get_related_cuis(cui, cat, relation_labels=['CHD','RN'])}\n",
    "    matched = []\n",
    "    for cui in cuis:\n",
    "        if cui in cuis_compare:\n",
    "            matched.append(cui)\n",
    "        elif cui in cuis_compare_parents:\n",
    "            matched.append(cui)\n",
    "        elif len(get_related_cuis(cui, cat, relation_labels=['CHD','RN']).intersection(cuis_compare)) > 0:\n",
    "            matched.append(cui)\n",
    "        else:\n",
    "            print(cui_to_name(cui, cat))\n",
    "            print(cuis_to_names(cuis_compare_parents, cat))\n",
    "            print(cuis_to_names(get_related_cuis(cui, cat, relation_labels=['CHD','RN']), cat))\n",
    "\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matched = []\n",
    "cuis_true_parents = {parent_cui for cui in cui_true for parent_cui in get_related_cuis(cui, cat, relation_labels=['CHD','RN'])}\n",
    "for cui_pred in cuis_pred:\n",
    "    if cui_pred in cuis_true or cui_pred in cuis_true_parents or get_related_cuis(cui_pred, cat, relation_labels=['CHD','RN']).intersection(cuis_true):\n",
    "        matched.append(cui_pred)\n",
    "\n",
    "len(matched)/len(cui_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches = base_matches.union(parent_true_matches).union(parent_pred_matches)\n",
    "cuis_to_names(matches, cat), cuis_to_names(cuis_true, cat), cuis_to_names(cuis_pred, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def precision(cuis_true: set[str], cuis_pred: set[str])->float:\n",
    "    cui_true_w_parents = cuis_true.union({parent_cui for cui in cui_true for parent_cui in get_related_cuis(cui, relation_labels=['CHD','RN'])})\n",
    "    true_positive = 0\n",
    "    print(cuis_to_names(cui_true_w_parents, cat))\n",
    "    for cui_pred in cuis_pred:\n",
    "        cui_pred_w_parents = set(cui_pred).union(get_related_cuis(cui_pred, relation_labels=['CHD','RN']))\n",
    "        if cui_pred_w_parents.intersection(cui_true_w_parents):\n",
    "            print(cui_to_name(cui_pred, cat), cuis_to_names(cui_pred_w_parents.intersection(cui_true_w_parents), cat))\n",
    "            true_positive += 1\n",
    "\n",
    "    return true_positive/len(cui_pred)\n",
    "\n",
    "precision(cui_true, cui_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "def get_related_cuis(cui:str, cat:CAT, relation_labels:list[str]|None=None, api_key:str=UMLS_API_KEY, umls_base_url:str=UMLS_BASE_URL, page_size:int=1000)->set[str]:\n",
    "    url = f\"{umls_base_url}/content/current/CUI/{cui}/relations\"\n",
    "    relation_label_str = \",\".join(relation_labels) if relation_labels else \"\"\n",
    "    params = {\"apiKey\": api_key, \"includeRelationLabels\": relation_label_str, \"pageNumber\": 1, \"pageSize\": page_size}\n",
    "    results = []\n",
    "    completed = False\n",
    "    while not completed:\n",
    "        response = requests.get(url, params)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            results.extend(response_json[\"result\"])\n",
    "            params[\"pageNumber\"] += 1\n",
    "            if response_json[\"pageCount\"] == 1:\n",
    "                completed = True\n",
    "        else:\n",
    "            print(f\"Failed to retrieve concept information for CUI: {cui}. Error code {response.status_code}\")\n",
    "            completed = True\n",
    "\n",
    "    related_cuis = {result[\"relatedId\"].split(\"/\")[-1] for result in results if \"relatedId\" in result}\n",
    "    return {cui for cui in related_cuis if cui in cat.cdb.cui2names}\n",
    "\n",
    "def get_child_to_parent_cui(org_cuis: list[str], cat)->dict[str, str]:\n",
    "    child_to_parent_cui = {}\n",
    "    for cui in org_cuis:\n",
    "        parent_cuis = get_related_cuis(cui, cat, relation_labels=['CHD','RN'])\n",
    "        parent_cuis = parent_cuis.intersection(org_cuis)\n",
    "        if parent_cuis:\n",
    "            child_to_parent_cui[cui] = next(iter(parent_cuis))\n",
    "\n",
    "    child_to_extend_parent_cui = {}\n",
    "    for child_cui in child_to_parent_cui.keys():\n",
    "        parent_exists = True\n",
    "        extend_parent_cui = child_cui\n",
    "        while parent_exists:\n",
    "            if extend_parent_cui in child_to_parent_cui:\n",
    "                extend_parent_cui = child_to_parent_cui[extend_parent_cui]\n",
    "            else:\n",
    "                parent_exists = False\n",
    "        if extend_parent_cui != child_cui:\n",
    "            child_to_extend_parent_cui[child_cui] = extend_parent_cui\n",
    "    return child_to_extend_parent_cui\n",
    "\n",
    "child_to_parent_cui = get_child_to_parent_cui(cui_to_entities.keys(), cat)\n",
    "{cui_to_name(child_cui, cat): cui_to_name(parent_cui, cat) for child_cui, parent_cui in child_to_parent_cui.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
