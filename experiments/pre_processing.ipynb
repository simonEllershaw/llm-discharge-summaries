{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from discharge_summaries.schemas.mimic import DischargeSummary, Note, Record\n",
    "from discharge_summaries.schemas.output import Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 23\n",
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "MIMIC_DIR = DATA_DIR / \"physionet.org\" / \"files\"\n",
    "\n",
    "MIMIC_III_DIR = MIMIC_DIR / \"mimiciii\" / \"1.4\"\n",
    "MIMIC_IV_DIR = MIMIC_DIR / \"mimiciv\" / \"2.2\" / \"note\"\n",
    "\n",
    "TRAIN_SAVE_PATH = DATA_DIR / \"train.pkl\"\n",
    "TEST_SAVE_PATH = DATA_DIR / \"test.pkl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in MIMIC III notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(MIMIC_III_DIR / \"NOTEEVENTS.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing\n",
    "\n",
    "Remove error and duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df[full_df[\"ISERROR\"] != 1]\n",
    "full_df.drop(\"ISERROR\", axis=1, inplace=True)\n",
    "full_df = full_df.drop_duplicates()\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_df), len(full_df[\"HADM_ID\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only Physician and discharge notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"CATEGORY\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.drop(\n",
    "    full_df[\n",
    "        (full_df[\"CATEGORY\"] == \"Discharge summary\")\n",
    "        & (full_df[\"DESCRIPTION\"] == \"Addendum\")\n",
    "    ].index\n",
    ")\n",
    "len(full_df), len(full_df[\"HADM_ID\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by HADM_ID and only keep rows with both a discharge summary and physician note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = full_df.groupby(\"HADM_ID\")\n",
    "df = grouped_df.filter(\n",
    "    lambda group: \"Discharge summary\" in group[\"CATEGORY\"].unique()\n",
    "    and \"Physician \" in group[\"CATEGORY\"].unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df[\"HADM_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    cleaned_text = re.sub(r\"\\n\\.\\n\", r\"\\n\\n\", text)\n",
    "    cleaned_text = re.sub(r\"\\n {2,}\", \"\\n\", cleaned_text)\n",
    "    cleaned_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", cleaned_text)\n",
    "    cleaned_text = re.sub(r\"\\n *(?=[a-z])\", \" \", cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "df[\"TEXT\"] = df[\"TEXT\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CHARTTIME\"] = df[\"CHARTTIME\"].fillna(full_df[\"CHARTDATE\"] + \" 23:59:59\")\n",
    "df = df.sort_values(by=[\"HADM_ID\", \"CHARTTIME\"])\n",
    "df = df.reset_index(drop=True)\n",
    "len(df), len(df[\"HADM_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bhc(discharge_summary_text: str) -> str:\n",
    "    start_pattern = r\"\\nBrief Hospital Course:\\n\"\n",
    "    end_pattern = r\"\\nMedications on Admission:\\n\"\n",
    "    match = re.search(\n",
    "        f\"{start_pattern}(.*?){end_pattern}\", discharge_summary_text, re.DOTALL\n",
    "    )\n",
    "    if not match:\n",
    "        return \"\"\n",
    "    return match.group(1)\n",
    "\n",
    "\n",
    "def extract_bhc_paragraphs(bhc: str) -> list[Paragraph]:\n",
    "    bhc_paragraphs = []\n",
    "    for idx, paragraph_text in enumerate(re.split(\"\\n\\n(?=#[^\\n]*:)\", bhc)):\n",
    "        if \"\\n\\n\" in paragraph_text:\n",
    "            return []\n",
    "        if idx == 0:\n",
    "            heading = \"\"\n",
    "            text = paragraph_text\n",
    "        else:\n",
    "            split = re.split(\":\", paragraph_text, maxsplit=1)\n",
    "            heading = split[0]\n",
    "            text = split[1].strip()\n",
    "        bhc_paragraphs.append(Paragraph(text=text, heading=heading))\n",
    "    return bhc_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for hadm_id, group_df in df.groupby(\"HADM_ID\"):\n",
    "    physician_notes = [\n",
    "        Note(\n",
    "            text=series[\"TEXT\"],\n",
    "            datetime=series[\"CHARTTIME\"],\n",
    "            category=series[\"CATEGORY\"],\n",
    "            description=series[\"DESCRIPTION\"],\n",
    "        )\n",
    "        for _, series in group_df[\n",
    "            group_df[\"CATEGORY\"] != \"Discharge summary\"\n",
    "        ].iterrows()\n",
    "    ]\n",
    "\n",
    "    discharge_summary_row = group_df[group_df[\"CATEGORY\"] == \"Discharge summary\"].iloc[\n",
    "        0\n",
    "    ]\n",
    "    bhc = extract_bhc(discharge_summary_row[\"TEXT\"])\n",
    "    bhc_paragraphs = extract_bhc_paragraphs(bhc)\n",
    "    if len(bhc_paragraphs) <= 1:\n",
    "        continue\n",
    "\n",
    "    discharge_summary = DischargeSummary(\n",
    "        text=discharge_summary_row[\"TEXT\"],\n",
    "        datetime=discharge_summary_row[\"CHARTTIME\"],\n",
    "        category=discharge_summary_row[\"CATEGORY\"],\n",
    "        description=discharge_summary_row[\"DESCRIPTION\"],\n",
    "        bhc=bhc,\n",
    "        bhc_paragraphs=bhc_paragraphs,\n",
    "    )\n",
    "\n",
    "    record = Record(\n",
    "        physician_notes=sorted(physician_notes),\n",
    "        discharge_summary=discharge_summary,\n",
    "        hadm_id=hadm_id,\n",
    "        subject_id=group_df[\"SUBJECT_ID\"].iloc[0],\n",
    "    )\n",
    "    dataset.append(record)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[3]\n",
    "for section in sample.discharge_summary.bhc_paragraphs:\n",
    "    print(section.heading, \":\", section.text)\n",
    "    print(\"*\" * 80)\n",
    "# print(sample.discharge_summary.bhc)\n",
    "# print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[RANDOM_SEED]\n",
    "print(dataset[10].discharge_summary.bhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.discharge_summary.bhc_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(\n",
    "    dataset, test_size=0.5, random_state=RANDOM_SEED\n",
    ")\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_SAVE_PATH, \"wb\") as out_file:\n",
    "    pickle.dump([record.dict() for record in train_dataset], out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_SAVE_PATH, \"wb\") as out_file:\n",
    "    pickle.dump([record.dict() for record in test_dataset], out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
