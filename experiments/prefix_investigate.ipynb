{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from medcat.cat import CAT\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.schemas.mimic import Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "TRAINING_DATASET_PATH = DATA_DIR / \"train.pkl\"\n",
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5.zip\"\n",
    ")\n",
    "RANDOM_SEED = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_DATASET_PATH, \"rb\") as in_file:\n",
    "    dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "dataset = dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CAT.load_model_pack(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_type_names = {\n",
    "    \"disorder\",\n",
    "    \"finding\",\n",
    "    \"morphologic abnormality\",\n",
    "    \"organism\",\n",
    "    \"physical object\",\n",
    "    \"clinical drug\",\n",
    "    \"medicinal product form\",\n",
    "    \"procedure\",\n",
    "    \"product\",\n",
    "}\n",
    "\n",
    "type_name_to_id = {\n",
    "    name: type_id for type_id, name in cat.cdb.addl_info[\"type_id2name\"].items()\n",
    "}\n",
    "\n",
    "type_ids_filter = [type_name_to_id[type_name] for type_name in filter_type_names]\n",
    "# type_ids_filter = [\n",
    "#     \"T020\",\n",
    "#     \"T190\",\n",
    "#     \"T049\",\n",
    "#     \"T019\",\n",
    "#     \"T047\",\n",
    "#     \"T050\",\n",
    "#     \"T033\",\n",
    "#     \"T037\",\n",
    "#     \"T048\",\n",
    "#     \"T191\",\n",
    "#     \"T046\",\n",
    "#     \"T184\",\n",
    "# ] + [\"T005\", \"T007\"]\n",
    "\n",
    "cui_filters = {\n",
    "    cui\n",
    "    for type_ids in type_ids_filter\n",
    "    for cui in cat.cdb.addl_info[\"type_id2cuis\"][type_ids]\n",
    "}\n",
    "cat.cdb.config.linking[\"filters\"][\"cuis\"] = cui_filters\n",
    "cat.cdb.config.linking[\"filters\"][\"cuis\"] = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.pipe.spacy_nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.pipe.spacy_nlp.disable_pipes([\"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cuis_from_text(text: str, cat: CAT):\n",
    "    text_ents = cat(text).ents if text else ()\n",
    "    return {ent._.cui for ent in text_ents}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What % of non empty headings can be annotated by MedCAT and then have matching annotations in the notes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# num_headings = 0\n",
    "# hits_search = []\n",
    "# partial_search = []\n",
    "# not_match_search = []\n",
    "# for doc in tqdm(dataset):\n",
    "#     doc_notes = \"\\n\".join(note.text.lower() for note in doc.physician_notes)\n",
    "#     for para in doc.discharge_summary.bhc_paragraphs:\n",
    "#         if para.heading == \"\":\n",
    "#             continue\n",
    "#         heading_split = [heading.lower() for heading in re.split(\"/\", para.heading)]\n",
    "#         for heading in heading_split:\n",
    "#             num_headings += 1\n",
    "#             if heading in doc_notes:\n",
    "#                 hits_search.append(para.heading)\n",
    "#                 break\n",
    "#             synonyms = {name.replace(\"~\", \" \") for ent in cat(heading).ents for name in cat.cdb.cui2names[ent._.cui]}\n",
    "#             if any(synonym in doc_notes for synonym in synonyms):\n",
    "#                 partial_search.append((para.heading, [synonym for synonym in synonyms if synonym in doc_notes]))\n",
    "#             else:\n",
    "#                 not_match_search.append(para.heading)\n",
    "# len(hits_search) / num_headings, len(partial_search) / num_headings, len(not_match_search) / num_headings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_headings = 0\n",
    "hits = []\n",
    "not_annotated = []\n",
    "partial_match = []\n",
    "strict_match = []\n",
    "no_match = []\n",
    "for doc in tqdm(dataset[:10]):\n",
    "    doc_note_cuis = {\n",
    "        cui\n",
    "        for note in doc.physician_notes\n",
    "        for cui in extract_cuis_from_text(note.text, cat)\n",
    "    }\n",
    "    for para in doc.discharge_summary.bhc_paragraphs:\n",
    "        if not para.heading:\n",
    "            continue\n",
    "        para_cuis = extract_cuis_from_text(para.heading, cat)\n",
    "        num_headings += 1\n",
    "        if para_cuis.issubset(doc_note_cuis):\n",
    "            hits.append(para.heading)\n",
    "        elif para_cuis.intersection(doc_note_cuis):\n",
    "            partial_match.append(para.heading)\n",
    "        elif para.heading.lower() in \"\\n\".join(\n",
    "            note.text.lower() for note in doc.physician_notes\n",
    "        ):\n",
    "            strict_match.append(para.heading)\n",
    "        elif not para_cuis:\n",
    "            not_annotated.append(para.heading)\n",
    "        else:\n",
    "            no_match.append(para.heading)\n",
    "len(hits) / num_headings, len(partial_match) / num_headings, len(\n",
    "    strict_match\n",
    ") / num_headings, len(no_match) / num_headings, len(not_annotated) / num_headings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = []\n",
    "for doc in tqdm(dataset):\n",
    "    for para in doc.discharge_summary.bhc_paragraphs:\n",
    "        if not para.heading:\n",
    "            continue\n",
    "        if not cat(para.heading).ents:\n",
    "            missed.append(para.heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"Acute Pancreatis\").ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missed) / len(\n",
    "    [\n",
    "        para\n",
    "        for doc in dataset\n",
    "        for para in doc.discharge_summary.bhc_paragraphs\n",
    "        if para.heading\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(hits) + len(partial_match) + len(strict_match)) / num_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0].discharge_summary.bhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"diarrhea\").ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    {\n",
    "        cui\n",
    "        for note in dataset[0].physician_notes\n",
    "        for cui in extract_cuis_from_text(note.text, cat)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.cdb.addl_info[\"type_id2name\"][\n",
    "    list(cat.cdb.cui2type_ids[cat.cdb.name2cuis[\"hypertension\"][0]])[0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_heading_cuis = [\n",
    "    {\n",
    "        cui\n",
    "        for para in doc.discharge_summary.bhc_paragraphs\n",
    "        for cui in extract_cuis_from_text(para.heading, cat)\n",
    "    }\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_note_cuis = [\n",
    "    {\n",
    "        cui\n",
    "        for note in doc.physician_notes\n",
    "        for cui in extract_cuis_from_text(note.text, cat)\n",
    "    }\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tp_fp_fn(actual_set, predicted_set) -> Tuple[float, float, float]:\n",
    "    true_positives = len(actual_set.intersection(predicted_set))\n",
    "    false_positives = len(predicted_set - actual_set)\n",
    "    false_negatives = len(actual_set - predicted_set)\n",
    "\n",
    "    return true_positives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_fp_fn = np.array(\n",
    "    [\n",
    "        calculate_tp_fp_fn(actual, pred)\n",
    "        for actual, pred in zip(dataset_heading_cuis, dataset_note_cuis)\n",
    "    ],\n",
    ")\n",
    "true_positives, false_positives, false_negatives = tp_fp_fn.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (\n",
    "    (true_positives / (true_positives + false_positives))\n",
    "    if true_positives + false_positives != 0\n",
    "    else 0.0\n",
    ")\n",
    "recall = (\n",
    "    (true_positives / (true_positives + false_negatives))\n",
    "    if true_positives + false_negatives != 0\n",
    "    else 0.0\n",
    ")\n",
    "f1 = (2 * precision * recall / (precision + recall)) if precision + recall != 0 else 0.0\n",
    "precision, recall, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
