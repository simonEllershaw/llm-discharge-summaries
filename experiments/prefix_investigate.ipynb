{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from medcat.cat import CAT\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.schemas.mimic import Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "TRAINING_DATASET_PATH = DATA_DIR / \"train.pkl\"\n",
    "MODEL_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"models\"\n",
    "    / \"umls_sm_pt2ch_533bab5115c6c2d6mimic_tuned_ebf8b5bb5099c274.zip\"\n",
    ")\n",
    "RANDOM_SEED = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_DATASET_PATH, \"rb\") as in_file:\n",
    "    dataset = [Record(**record) for record in pickle.load(in_file)]\n",
    "dataset = dataset[:10]\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CAT.load_model_pack(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.pipe.spacy_nlp.disable_pipes([\"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_type_names = {\n",
    "#     \"disorder\",\n",
    "#     \"finding\",\n",
    "# }\n",
    "\n",
    "# type_name_to_id = {\n",
    "#     name: type_id for type_id, name in cat.cdb.addl_info[\"type_id2name\"].items()\n",
    "# }\n",
    "\n",
    "# type_ids_filter = [type_name_to_id[type_name] for type_name in filter_type_names]\n",
    "# type_ids_filter = [\n",
    "#     \"T020\",\n",
    "#     \"T190\",\n",
    "#     \"T049\",\n",
    "#     \"T019\",\n",
    "#     \"T047\",\n",
    "#     \"T050\",\n",
    "#     \"T033\",\n",
    "#     \"T037\",\n",
    "#     \"T048\",\n",
    "#     \"T191\",\n",
    "#     \"T046\",\n",
    "#     \"T184\",\n",
    "# ] + [\"T005\", \"T007\"]\n",
    "# cui_filters = {\n",
    "#     cui\n",
    "#     for type_ids in type_ids_filter\n",
    "#     for cui in cat.cdb.addl_info[\"type_id2cuis\"][type_ids]\n",
    "# }\n",
    "# cat.cdb.config.linking[\"filters\"][\"cuis\"] = cui_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cuis_from_text(text: str, cat: CAT):\n",
    "    text_ents = cat(text).ents if text else ()\n",
    "    return {ent._.cui for ent in text_ents}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What % of non empty headings can be annotated by MedCAT and then have matching annotations in the notes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_headings = 0\n",
    "hits = 0\n",
    "not_annotated = 0\n",
    "not_match = 0\n",
    "partial_match = 0\n",
    "for doc in tqdm(dataset):\n",
    "    doc_note_cuis = {\n",
    "        cui\n",
    "        for note in doc.physician_notes\n",
    "        for cui in extract_cuis_from_text(note.text, cat)\n",
    "    }\n",
    "    for para in doc.discharge_summary.bhc_paragraphs:\n",
    "        if not para.text:\n",
    "            continue\n",
    "        para_cuis = extract_cuis_from_text(para.heading, cat)\n",
    "        num_headings += 1\n",
    "        if not para_cuis:\n",
    "            not_annotated += 1\n",
    "        elif not para_cuis.issubset(doc_note_cuis):\n",
    "            if para_cuis.intersection(doc_note_cuis):\n",
    "                partial_match += 1\n",
    "            else:\n",
    "                not_match += 1\n",
    "        else:\n",
    "            hits += 1\n",
    "hits / num_headings, partial_match / num_headings, not_match / num_headings, not_annotated / num_headings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_heading_cuis = [\n",
    "    {\n",
    "        cui\n",
    "        for para in doc.discharge_summary.bhc_paragraphs\n",
    "        for cui in extract_cuis_from_text(para.heading, cat)\n",
    "    }\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_note_cuis = [\n",
    "    {\n",
    "        cui\n",
    "        for note in doc.physician_notes\n",
    "        for cui in extract_cuis_from_text(note.text, cat)\n",
    "    }\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tp_fp_fn(actual_set, predicted_set) -> Tuple[float, float, float]:\n",
    "    true_positives = len(actual_set.intersection(predicted_set))\n",
    "    false_positives = len(predicted_set - actual_set)\n",
    "    false_negatives = len(actual_set - predicted_set)\n",
    "\n",
    "    return true_positives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_fp_fn = np.array(\n",
    "    [\n",
    "        calculate_tp_fp_fn(actual, pred)\n",
    "        for actual, pred in zip(dataset_heading_cuis, dataset_note_cuis)\n",
    "    ],\n",
    ")\n",
    "true_positives, false_positives, false_negatives = tp_fp_fn.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (\n",
    "    (true_positives / (true_positives + false_positives))\n",
    "    if true_positives + false_positives != 0\n",
    "    else 0.0\n",
    ")\n",
    "recall = (\n",
    "    (true_positives / (true_positives + false_negatives))\n",
    "    if true_positives + false_negatives != 0\n",
    "    else 0.0\n",
    ")\n",
    "f1 = (2 * precision * recall / (precision + recall)) if precision + recall != 0 else 0.0\n",
    "precision, recall, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
