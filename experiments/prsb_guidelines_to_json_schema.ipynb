{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import ClassVar, Dict, List\n",
    "\n",
    "import openpyxl\n",
    "import PyPDF2\n",
    "import tiktoken\n",
    "from pydantic import BaseModel\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDELINES_DIR = Path.cwd().parent / \"guidelines\"\n",
    "GUIDELINES_EXCEL_PATH = GUIDELINES_DIR / \"eDischarge-Summary-v2.1-1st-Feb-21.xlsx\"\n",
    "GUIDELINES_IMPLEMENTATION_PDF_PATH = (\n",
    "    GUIDELINES_DIR\n",
    "    / \"eDischarge-Summary-Maintenance-Release-Implementation-Guidance-Report-v2.1-23.1.19.pdf\"\n",
    ")\n",
    "\n",
    "GUIDELINES_JSON_PATH = GUIDELINES_DIR / \"eDischarge-Summary-v2.1-1st-Feb-21_schema.json\"\n",
    "\n",
    "DATABASE_SECTIONS = {\n",
    "    \"Patient demographics\",\n",
    "    \"GP practice\",\n",
    "    \"Referrer detailsDischarge details\",\n",
    "    \"Medications and Medical Devices\",\n",
    "    \"Person completing record\",\n",
    "    \"Distribution list\",\n",
    "}\n",
    "\n",
    "\n",
    "TOKENIZER = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = openpyxl.load_workbook(GUIDELINES_EXCEL_PATH)[\"Sheet1\"]\n",
    "row_records = list(sheet.iter_rows(values_only=True, min_row=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_camel_case(text: str) -> str:\n",
    "    return re.sub(r\"\\W+\", \"_\", text.strip().lower())\n",
    "\n",
    "\n",
    "class Row(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    cardinality: str\n",
    "    data_type: str\n",
    "    values: str\n",
    "    do_not_use: bool\n",
    "\n",
    "    def from_record(row: List[str]) -> \"Row\":\n",
    "        cleaned_values = [unidecode(value).strip() if value else \"\" for value in row]\n",
    "        cleaned_values[0] = to_camel_case(cleaned_values[0])\n",
    "        return Row(\n",
    "            name=cleaned_values[0],\n",
    "            description=cleaned_values[1],\n",
    "            cardinality=cleaned_values[2],\n",
    "            data_type=cleaned_values[3],\n",
    "            values=cleaned_values[4],\n",
    "            do_not_use=(cleaned_values[5] == \"Y\"),\n",
    "        )\n",
    "\n",
    "\n",
    "class SectionRows(BaseModel):\n",
    "    SECTION_ROW_IDX: ClassVar[int] = 1\n",
    "    ELEMENT_HEADER_ROW_IDX: ClassVar[int] = 2\n",
    "\n",
    "    section_row: Row\n",
    "    element_rows: List[Row]\n",
    "\n",
    "    @classmethod\n",
    "    def from_record(cls, section_row_records: List[List[str]]) -> \"SectionRows\":\n",
    "        return SectionRows(\n",
    "            section_row=Row.from_record(\n",
    "                section_row_records[SectionRows.SECTION_ROW_IDX]\n",
    "            ),\n",
    "            element_rows=[\n",
    "                Row.from_record(row_record)\n",
    "                for row_record in section_row_records[\n",
    "                    SectionRows.ELEMENT_HEADER_ROW_IDX + 1 :\n",
    "                ]\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "def get_cluster_rows(rows: List[Row]) -> List[Row]:\n",
    "    cluster_rows = []\n",
    "    if len(rows) <= 1:\n",
    "        raise ValueError(f\"Only the header of a cluster was found. {rows}\")\n",
    "    # First row is the header\n",
    "    for row in rows[1:]:\n",
    "        # Assume second row is start of cluster (if record entry is a cluster)\n",
    "        if row.name == f\"end_of_{rows[0].name}\":\n",
    "            break\n",
    "        cluster_rows.append(row)\n",
    "\n",
    "    return cluster_rows\n",
    "\n",
    "\n",
    "def row_to_string_schema(row: Row) -> Dict:\n",
    "    return {\n",
    "        \"description\": row.description,\n",
    "        \"type\": \"string\",\n",
    "    }\n",
    "\n",
    "\n",
    "def row_to_array_schema(row: Row) -> Dict:\n",
    "    return {\n",
    "        \"description\": row.description,\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "            \"type\": \"string\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def rows_to_object_schema(rows: List[Row]) -> Dict:\n",
    "    return {\"type\": \"object\", \"properties\": element_rows_to_json_schema(rows)}\n",
    "\n",
    "\n",
    "def element_rows_to_json_schema(element_rows: List[Row]) -> Dict:\n",
    "    element_schema = {}\n",
    "\n",
    "    row_idx = 0\n",
    "    while row_idx < len(element_rows):\n",
    "        element_row = element_rows[row_idx]\n",
    "        if element_row.do_not_use:\n",
    "            row_idx += 1\n",
    "            continue\n",
    "        elif not element_row.values and \"record entry\" in element_row.description:\n",
    "            record_entry_rows = element_rows[row_idx + 1 :]\n",
    "            if len(record_entry_rows) == 1:\n",
    "                items = row_to_string_schema(record_entry_rows[0])\n",
    "            else:\n",
    "                items = rows_to_object_schema(record_entry_rows)\n",
    "            row_schema = {\n",
    "                \"description\": element_row.description,\n",
    "                \"type\": \"array\",\n",
    "                \"items\": items,\n",
    "            }\n",
    "            row_idx = len(element_rows)\n",
    "        elif element_row.name.endswith(\"item_entry\"):\n",
    "            cluster_rows = get_cluster_rows(element_rows[row_idx + 1 :])\n",
    "            cluster_schema = rows_to_object_schema(cluster_rows)\n",
    "            row_schema = {\n",
    "                \"description\": element_row.description,\n",
    "                \"type\": \"array\",\n",
    "                \"items\": cluster_schema,\n",
    "            }\n",
    "            row_idx += len(cluster_rows) + 2\n",
    "        elif element_row.cardinality.startswith(\"0 to many\"):\n",
    "            row_schema = row_to_array_schema(element_row)\n",
    "        elif element_row.name.endswith(\"cluster\"):\n",
    "            cluster_rows = get_cluster_rows(element_rows[row_idx:])\n",
    "            # Needs description\n",
    "            row_schema = rows_to_object_schema(cluster_rows)\n",
    "            row_idx += len(cluster_rows) + 1\n",
    "        else:\n",
    "            row_schema = row_to_string_schema(element_row)\n",
    "\n",
    "        element_schema[element_row.name] = row_schema\n",
    "        row_idx += 1\n",
    "    return element_schema\n",
    "\n",
    "\n",
    "def create_section_json_schema_from_rows(section_rows: SectionRows) -> Dict:\n",
    "    elements_schema = element_rows_to_json_schema(section_rows.element_rows)\n",
    "\n",
    "    if (\n",
    "        len(elements_schema) == 1\n",
    "        and list(elements_schema.keys())[0] == section_rows.section_row.name\n",
    "    ):\n",
    "        # If only one element squash the section and element schema together\n",
    "        single_element_schema = next(iter(elements_schema.values()))\n",
    "        joint_description = \" \".join(\n",
    "            text\n",
    "            for text in (\n",
    "                section_rows.section_row.description,\n",
    "                single_element_schema.pop(\"description\", \"\"),\n",
    "            )\n",
    "        )\n",
    "        return {\n",
    "            \"description\": joint_description,\n",
    "            **single_element_schema,\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"description\": section_rows.section_row.description,\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": elements_schema,\n",
    "        }\n",
    "\n",
    "\n",
    "def create_schema_from_row_records(row_records: List[List[str]]) -> Dict:\n",
    "    # Sections separated by empty rows\n",
    "    sections = []\n",
    "    section_row_records: List[List[str]] = []\n",
    "    for row in row_records:\n",
    "        if all(element is None for element in row):\n",
    "            sections.append(SectionRows.from_record(section_row_records))\n",
    "            section_row_records = []\n",
    "        else:\n",
    "            section_row_records.append(row)\n",
    "    sections.append(SectionRows.from_record(section_row_records))\n",
    "\n",
    "    sections_schema = {\n",
    "        section.section_row.name: create_section_json_schema_from_rows(section)\n",
    "        for section in sections\n",
    "    }\n",
    "\n",
    "    return {\"type\": \"object\", \"properties\": sections_schema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = create_schema_from_row_records(row_records)\n",
    "GUIDELINES_JSON_PATH.write_text(json.dumps(schema, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDELINES_JSON_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camelcase_database_sections = {to_camel_case(section) for section in DATABASE_SECTIONS}\n",
    "schema[\"properties\"] = {\n",
    "    k: v\n",
    "    for k, v in schema[\"properties\"].items()\n",
    "    if k not in camelcase_database_sections\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TOKENIZER.encode(json.dumps(schema)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfReader(GUIDELINES_IMPLEMENTATION_PDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [line for page in reader.pages for line in page.extract_text().split(\"\\n\")]\n",
    "text = [\n",
    "    re.sub(\n",
    "        (\n",
    "            \"(PRSB eDischarge Summary  – Implementation Guidance  V2.1)|(January 2019 \"\n",
    "            r\" Page \\d+  )|(January 2019  Page \\d+  )\"\n",
    "        ),\n",
    "        \"\",\n",
    "        line,\n",
    "    ).strip()\n",
    "    for line in text\n",
    "]\n",
    "text = [re.sub(\" {2,}\", \" \", line) for line in text]\n",
    "text = [re.sub(\"reco rd\", \"record\", line) for line in text]\n",
    "text = [line for line in text if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_heading_idx = len(text)\n",
    "heading_to_text = {}\n",
    "for heading_idx, line in enumerate(reversed(text)):\n",
    "    if re.match(r\"^4\\.\\d+ [A-Za-z ]+$\", line):\n",
    "        section_text = \"\\n\".join(text[len(text) - heading_idx : last_heading_idx])\n",
    "        section_text = re.sub(r\"\\d+.\\d+.\\d+ \", \"\", section_text)\n",
    "        section_text = re.sub(\"\\n(?=[a-z])\", \" \", section_text)\n",
    "        section_text = unidecode(section_text)\n",
    "        heading = to_camel_case(re.sub(r\"\\d+.\\d+ \", \"\", line))\n",
    "\n",
    "        heading_to_text[heading] = section_text\n",
    "        last_heading_idx = len(text) - heading_idx - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for property_heading, property_body in schema[\"properties\"].items():\n",
    "    if property_heading in heading_to_text:\n",
    "        property_body[\"description\"] += f\"\\n{heading_to_text[property_heading]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TOKENIZER.encode(json.dumps(schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDELINES_JSON_PATH.write_text(json.dumps(schema, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDELINES_JSON_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
