{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from discharge_summaries.openai_llm.chat_models import AzureOpenAIChatModel\n",
    "from discharge_summaries.openai_llm.message import Message, Role\n",
    "from discharge_summaries.openai_llm.token_count import (\n",
    "    num_tokens_from_messages_azure_engine,\n",
    ")\n",
    "from discharge_summaries.schemas.mimic import Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "TRAINING_DATASET_PATH = DATA_DIR / \"train_all_ds.pkl\"\n",
    "RANDOM_SEED = 23\n",
    "AZURE_ENGINE = \"gpt-4\"\n",
    "AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "# AZURE_ENGINE = \"gpt-35-turbo\"\n",
    "# AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "\n",
    "GUIDELINES_JSON_SCHEMA_PATH = (\n",
    "    Path.cwd().parent\n",
    "    / \"guidelines\"\n",
    "    / \"eDischarge-Summary-v2.1-1st-Feb-21_pydantic.json\"\n",
    ")\n",
    "\n",
    "INPUT_FPATH = DATA_DIR / \"prsb_example.txt\"\n",
    "TOKENIZER = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path.cwd() / \"output\" / INPUT_FPATH.stem\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir(parents=True)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAIChatModel(\n",
    "    api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=AZURE_API_VERSION,\n",
    "    engine=AZURE_ENGINE,\n",
    "    temperature=0,\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_to_include = {\n",
    "    \"social_context\",\n",
    "    \"participation_in_research\",\n",
    "    \"admission_details\",\n",
    "    \"individual_requirements\",\n",
    "    \"diagnoses\",\n",
    "    \"procedures\",\n",
    "    \"clinical_summary\",\n",
    "    \"assessment_scale\",\n",
    "    \"allergies_and_adverse_reactions\",\n",
    "    \"patient_and_carer_concerns_expectations_and_wishes\",\n",
    "    \"information_and_advice_given\",\n",
    "    \"plan_and_requested_actions\",\n",
    "    \"safety_alerts\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physican_notes = [\n",
    "    Note(\n",
    "        text=INPUT_FPATH.read_text(),\n",
    "        datetime=\"2021-01-01 17:00:00\",\n",
    "        category=\"\",\n",
    "        description=\"\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove indents (save tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidelines_json_schema_json = json.loads(GUIDELINES_JSON_SCHEMA_PATH.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_sections = {\n",
    "    section_name\n",
    "    for section_name in guidelines_json_schema_json[\"properties\"].keys()\n",
    "    if section_name not in sections_to_include\n",
    "}\n",
    "ignored_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidelines_json_schema_json[\"properties\"] = {\n",
    "    k: v\n",
    "    for k, v in guidelines_json_schema_json[\"properties\"].items()\n",
    "    if k in sections_to_include\n",
    "}\n",
    "guidelines_json_schema_str = json.dumps(guidelines_json_schema_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output_dir.parent / \"reduced_schema.json\").write_text(\n",
    "    json.dumps(guidelines_json_schema_json, indent=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = Message(\n",
    "    role=Role.SYSTEM,\n",
    "    content=f\"\"\"You are a consultant doctor tasked with writing a patients discharge summary.\n",
    "Only the information in the physician notes provided by the user can be used for this task.\n",
    "Each physician note has a title of the format Physician Note [number]: [timestamp].\n",
    "\n",
    "The discharge summary must be written in accordance with the following json schema.\n",
    "{guidelines_json_schema_str}\n",
    "If the information is not present to fill in a field, answer it with an empty string.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TOKENIZER.encode(SYSTEM_MESSAGE.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes_string(notes: List[Note]):\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"Physician Note {idx+1}: {note.datetime}\\n{note.text}\"\n",
    "        for idx, note in enumerate(notes)\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_discharge_summary(\n",
    "    notes: List[Note], max_prompt_tokens=31000\n",
    ") -> List[Message]:\n",
    "    notes_string = generate_notes_string(notes)\n",
    "    user_message_content = (\n",
    "        \"Generate the discharge summary json given the following physician\"\n",
    "        f\" notes\\n\\n{notes_string}\"\n",
    "    )\n",
    "    prompt_messages = [\n",
    "        SYSTEM_MESSAGE,\n",
    "        Message(role=Role.USER, content=user_message_content),\n",
    "    ]\n",
    "\n",
    "    num_prompt_tokens = num_tokens_from_messages_azure_engine(\n",
    "        prompt_messages, AZURE_ENGINE, AZURE_API_VERSION\n",
    "    )\n",
    "    if num_prompt_tokens > max_prompt_tokens:\n",
    "        raise ValueError(\n",
    "            f\"Prompt has {num_prompt_tokens} tokens, which is greater than the max of\"\n",
    "            f\" {max_prompt_tokens}.\"\n",
    "        )\n",
    "\n",
    "    return prompt_messages + [llm.query(prompt_messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notes = generate_discharge_summary(physican_notes)\n",
    "(output_dir / \"pred.json\").write_text(\n",
    "    json.dumps(json.loads(output_notes[-1].content), indent=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_fpath = INPUT_FPATH.parent / f\"{INPUT_FPATH.stem}_gt.json\"\n",
    "gt_json = {\n",
    "    section_name: v\n",
    "    for section_name, v in json.loads(gt_fpath.read_text()).items()\n",
    "    if section_name in sections_to_include\n",
    "}\n",
    "(output_dir / \"gt.json\").write_text(json.dumps(gt_json, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
