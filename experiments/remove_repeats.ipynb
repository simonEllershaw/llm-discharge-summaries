{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "AZURE_ENGINE = \"gpt-35-turbo-16k\"\n",
    "AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "TOKENIZER = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician_notes = pd.read_csv(MIMIC_III_DIR / \"physician_notes.csv\")\n",
    "grouped_physician_notes_df = physician_notes.groupby(\"HADM_ID\")\n",
    "hadm_id, physician_notes_hadm_id_df = next(iter(physician_notes.groupby(\"HADM_ID\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes_string(physician_notes_df: pd.DataFrame):\n",
    "    # Could be smarter here alot of text overlap\n",
    "    physician_notes_df_filtered = physician_notes_df[\n",
    "        [\"CHARTTIME\", \"TEXT\"]\n",
    "    ].drop_duplicates()\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"Physician Note {idx+1}: {note['CHARTTIME']}\\n{note['TEXT']}\"\n",
    "        for idx, note in physician_notes_df_filtered.sort_values(\"CHARTTIME\").iterrows()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_string_lengths = [\n",
    "    len(TOKENIZER.encode(generate_notes_string(group)))\n",
    "    for _, group in tqdm(\n",
    "        physician_notes.groupby(\"HADM_ID\"),\n",
    "        total=len(physician_notes[\"HADM_ID\"].unique()),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes_stringv2(physician_notes_df: pd.DataFrame):\n",
    "    physician_notes_df_filtered = (\n",
    "        physician_notes_df[[\"CHARTTIME\", \"TEXT\"]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    added_sections = set()\n",
    "    physician_notes = []\n",
    "    for idx, note in physician_notes_df_filtered.sort_values(\"CHARTTIME\").iterrows():\n",
    "        new_sections = \"\"\n",
    "        for note_section in re.split(\n",
    "            \"\\n(?=^[^\\n].*?:)\", note[\"TEXT\"], flags=re.MULTILINE\n",
    "        ):\n",
    "            if note_section not in added_sections:\n",
    "                new_sections += \"\\n\" + note_section\n",
    "                added_sections.add(note_section)\n",
    "        physician_notes.append(\n",
    "            f\"Physician Note {idx+1}: {note['CHARTTIME']}{new_sections}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(physician_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_string_lengths = [\n",
    "    len(TOKENIZER.encode(generate_notes_stringv2(group)))\n",
    "    for _, group in tqdm(\n",
    "        physician_notes.groupby(\"HADM_ID\"),\n",
    "        total=len(physician_notes[\"HADM_ID\"].unique()),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(naive_string_lengths), np.median(v2_string_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(naive_string_lengths), np.mean(v2_string_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(naive_string_lengths), np.max(v2_string_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(naive_string_lengths, 95), np.percentile(v2_string_lengths, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 for length in v2_string_lengths if length < 15000) / len(v2_string_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(naive_string_lengths).max(), np.array(v2_string_lengths).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
