{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import jsonref\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from discharge_summaries.openai_llm.chat_models import AzureOpenAIChatModel\n",
    "from discharge_summaries.openai_llm.message import Message, Role\n",
    "from discharge_summaries.schemas.prsb_guidelines import DischargeSummary\n",
    "from discharge_summaries.structured_data_extractors.mimic import (\n",
    "    MIMICStructuredDataExtractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "AZURE_ENGINE = \"gpt-3-turbo-16k\"\n",
    "AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "TOKENIZER = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician_notes_df = pd.read_csv(MIMIC_III_DIR / \"physician_notes.csv\")\n",
    "discharge_summary_df = pd.read_csv(MIMIC_III_DIR / \"discharge_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data_extractor = MIMICStructuredDataExtractor(MIMIC_III_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm_ids = discharge_summary_df[\"HADM_ID\"].unique()\n",
    "random.Random(23).shuffle(hadm_ids)\n",
    "hadm_id = hadm_ids[0]\n",
    "hadm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician_notes_hadm_id_df = physician_notes_df[\n",
    "    physician_notes_df[\"HADM_ID\"] == hadm_ids[0]\n",
    "]\n",
    "len(physician_notes_hadm_id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data_summary = structured_data_extractor.complete_prsb_discharge_summary(\n",
    "    hadm_id\n",
    ")\n",
    "structured_data_summary_dict = structured_data_summary.dict()\n",
    "medications_structured_data = structured_data_summary_dict.pop(\n",
    "    \"medications_and_medical_devices\"\n",
    ")\n",
    "procedures_structured_data = structured_data_summary_dict.pop(\"procedures\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_key_from_schema(schema: Union[Dict, List, str], remove_key: str):\n",
    "    if isinstance(schema, dict):\n",
    "        if remove_key in schema.keys():\n",
    "            del schema[remove_key]\n",
    "        for key in schema.keys():\n",
    "            remove_key_from_schema(schema[key], remove_key)\n",
    "    elif isinstance(schema, list):\n",
    "        for item in schema:\n",
    "            remove_key_from_schema(item, remove_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_ref_dict_to_dict(json_ref_dict: Dict) -> Dict:\n",
    "    for k, v in json_ref_dict.items():\n",
    "        if type(v) == jsonref.JsonRef:\n",
    "            json_ref_dict[k] = json_ref_dict_to_dict(dict(v))\n",
    "        elif type(v) == dict:\n",
    "            json_ref_dict[k] = json_ref_dict_to_dict(v)\n",
    "    return json_ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = jsonref.loads(DischargeSummary.schema_json(), jsonschema=True)\n",
    "json_schema = json_ref_dict_to_dict(json_schema)\n",
    "json_schema.pop(\"definitions\")\n",
    "medications_schema = json_schema[\"properties\"].pop(\"medications_and_medical_devices\")\n",
    "procedures_schema = json_schema[\"properties\"].pop(\"procedures\")\n",
    "remove_key_from_schema(json_schema, \"required\")\n",
    "# Keep top level title\n",
    "remove_key_from_schema(json_schema[\"properties\"], \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_previously_filled_schema_fields(schema: Dict, filled_schema: Dict) -> Dict:\n",
    "    for key, value in filled_schema.items():\n",
    "        if isinstance(value, dict):\n",
    "            schema[key][\"properties\"] = {\n",
    "                property_key: property_value\n",
    "                for property_key, property_value in remove_previously_filled_schema_fields(\n",
    "                    schema[key][\"properties\"], value\n",
    "                ).items()\n",
    "                if property_value\n",
    "            }\n",
    "        else:\n",
    "            if value:\n",
    "                del schema[key]\n",
    "    return schema\n",
    "\n",
    "\n",
    "json_schema[\"properties\"] = remove_previously_filled_schema_fields(\n",
    "    json_schema[\"properties\"], structured_data_summary_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TOKENIZER.encode(json.dumps(json_schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes_string(physician_notes_df: pd.DataFrame):\n",
    "    # Could be smarter here alot of text overlap\n",
    "    physician_notes_df_filtered = (\n",
    "        physician_notes_df[[\"CHARTTIME\", \"TEXT\"]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    added_sections = set()\n",
    "    physician_notes = []\n",
    "    for idx, note in physician_notes_df_filtered.sort_values(\"CHARTTIME\").iterrows():\n",
    "        new_sections = \"\"\n",
    "        for note_section in re.split(\n",
    "            \"\\n(?=^[^\\n].*?:)\", note[\"TEXT\"], flags=re.MULTILINE\n",
    "        ):\n",
    "            if note_section not in added_sections:\n",
    "                new_sections += \"\\n\" + note_section\n",
    "                added_sections.add(note_section)\n",
    "        physician_notes.append(\n",
    "            f\"Physician Note {idx+1}: {note['CHARTTIME']}{new_sections}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(physician_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_message(json_schema: Dict) -> Message:\n",
    "    return Message(\n",
    "        role=Role.SYSTEM,\n",
    "        content=f\"\"\"You are a consultant doctor tasked with writing a patients discharge summary.\n",
    "Only the information in the physician notes provided by the user can be used for this task.\n",
    "Each physician note has a title of the format Physician Note [number]: [timestamp].\n",
    "\n",
    "The discharge summary must be written in accordance with the following json schema.\n",
    "{json.dumps(json_schema)}\n",
    "If the information is not present to fill in a field, answer it with an empty string or list.\n",
    "\"\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAIChatModel(\n",
    "    api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=AZURE_API_VERSION,\n",
    "    engine=AZURE_ENGINE,\n",
    "    temperature=0,\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_discharge_summary(\n",
    "    physician_note_df: pd.DataFrame,\n",
    "    json_schema: Dict,\n",
    "    llm: AzureOpenAIChatModel,\n",
    "    max_prompt_tokens=15000,\n",
    ") -> List[Message]:\n",
    "    system_message = create_system_message(json_schema)\n",
    "\n",
    "    notes_string = generate_notes_string(physician_note_df)\n",
    "    user_message_content = (\n",
    "        \"Generate the discharge summary json given the following physician\"\n",
    "        f\" notes\\n\\n{notes_string}\"\n",
    "    )\n",
    "    prompt_messages = [\n",
    "        system_message,\n",
    "        Message(role=Role.USER, content=user_message_content),\n",
    "    ]\n",
    "\n",
    "    num_prompt_tokens = sum(\n",
    "        len(TOKENIZER.encode(message.content)) for message in prompt_messages\n",
    "    )\n",
    "    print(num_prompt_tokens)\n",
    "    if num_prompt_tokens > max_prompt_tokens:\n",
    "        raise ValueError(\n",
    "            f\"Prompt has {num_prompt_tokens} tokens, which is greater than the max of\"\n",
    "            f\" {max_prompt_tokens}.\"\n",
    "        )\n",
    "\n",
    "    return prompt_messages + [llm.query(prompt_messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = generate_discharge_summary(physician_notes_hadm_id_df, json_schema, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path.cwd() / \"output\" / f\"mimic_hadm_id_{int(hadm_id)}\"\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output_path / \"json_schema.json\").write_text(json.dumps(json_schema, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_notes = \"\\n\\n\".join(\n",
    "    f\"Physician Note {idx+1}: {note['CHARTTIME']}\\n{note['TEXT']}\"\n",
    "    for idx, note in physician_notes_hadm_id_df.sort_values(\"CHARTTIME\").iterrows()\n",
    ")\n",
    "(output_path / \"physician_notes.txt\").write_text(combined_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output_path / \"discharge_summary.json\").write_text(\n",
    "    json.dumps(json.loads(messages[-1].content), indent=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output_path / \"prompts.json\").write_text(\n",
    "    json.dumps([message.dict() for message in messages[:-1]], indent=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_hadm_id_ds = discharge_summary_df[discharge_summary_df[\"HADM_ID\"] == hadm_id][\n",
    "    \"TEXT\"\n",
    "].iloc[0]\n",
    "(output_path / \"mimic_discharge_summary.txt\").write_text(mimic_hadm_id_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medications_structured_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
