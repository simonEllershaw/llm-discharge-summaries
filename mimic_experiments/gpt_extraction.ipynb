{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from discharge_summaries.schemas.mimic import BHC\n",
    "import pickle\n",
    "from discharge_summaries.openai_llm.chat_models import AzureOpenAIChatModel\n",
    "from discharge_summaries.openai_llm.message import Message, Role\n",
    "import os\n",
    "from discharge_summaries.snomed.lookup import SnomedLookup\n",
    "from discharge_summaries.snomed.phrase_matcher import SnomedPhraseMatcher\n",
    "from dotenv import load_dotenv\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "BHC_FPATH = MIMIC_III_DIR / \"BHCS.json\"\n",
    "PHYSICIAN_NOTE_FPATH = MIMIC_III_DIR / \"physician_notes_mimic.csv\"\n",
    "\n",
    "SNOMED_DIR = Path.cwd().parent / \"data\" / \"snomed\"\n",
    "TUNED_PHRASE_MATCHER_FPATH = SNOMED_DIR / \"tuned_snomed_phrase_matcher.pkl\"\n",
    "PROMPT_MESSAGE_FPATH = Path.cwd() / \"prompt_message.txt\"\n",
    "AZURE_ENGINE = \"gpt-35-turbo\"\n",
    "AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "EXAMPLE_DIR = Path.cwd() / \"example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_phrase_matcher = pickle.load(TUNED_PHRASE_MATCHER_FPATH.open(\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_lookup = SnomedLookup.load(SNOMED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_sci_lg\", disable=[\"ner\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAIChatModel(\n",
    "    api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=AZURE_API_VERSION,\n",
    "    engine=AZURE_ENGINE,\n",
    "    temperature=0,\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhcs = [BHC(**bhc_dict) for bhc_dict in json.loads(BHC_FPATH.read_text())]\n",
    "physician_notes = pd.read_csv(PHYSICIAN_NOTE_FPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, bhc in enumerate(bhcs[:100]):\n",
    "    print(idx)\n",
    "    print(bhc.assessment_and_plan)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bhc = bhcs[10]\n",
    "sample_physician_notes = physician_notes[physician_notes[\"HADM_ID\"] == sample_bhc.hadm_id].sort_values(\"CHARTTIME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "(EXAMPLE_DIR / \"bhc.txt\").write_text(sample_bhc.full_text)\n",
    "with (EXAMPLE_DIR / \"bhc.txt\").open(\"a\") as f:\n",
    "    f.write(f\"\\n{'*'*80}\\n{json.dumps(sample_bhc.dict(), indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bit long I think... Check average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = \"\\n\\n\".join(bhc.assessment_and_plan for bhc in bhcs[:3])\n",
    "first_para_system_message = Message(\n",
    "    role=Role.SYSTEM,\n",
    "    content=f\"\"\"You are a consultant doctor completing a medical discharge summary.\n",
    "Your task is to write the first paragraph of the summary.\n",
    "The paragraph should be 30 words long.\n",
    "The paragraph must include the patient's:\n",
    "- Age\n",
    "- Gender\n",
    "- Past medical history\n",
    "- Reason for hospital admission\n",
    "This information can be found in the admission note provided by the user.\n",
    "\n",
    "The following are examples of first paragraphs:\n",
    "{examples}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_para_user_message = Message(\n",
    "    role=Role.USER,\n",
    "    content=f\"\"\"Admission Note\n",
    "\n",
    "{sample_physician_notes.iloc[0][\"TEXT\"]}\n",
    "Please write the first paragraph of the discharge summary using the admission note and the requirements given in the system message.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_para_response = llm.query([first_para_system_message, first_para_user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_delimiter = \"\\n\" + (\"*\" * 80) + \"\\n\"\n",
    "message_strings = message_delimiter.join(f\"{message.role}\\n{message.content}\" for message in [first_para_system_message, first_para_user_message, first_para_response])\n",
    "message_strings += f\"\\n{message_delimiter}\\nMIMIC BHC\\n{sample_bhc.assessment_and_plan}\"\n",
    "(EXAMPLE_DIR / \"first_para.txt\").write_text(message_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = \"\\n\\n\".join(\"\\n\".join(para.heading for para in bhc.problem_sections if snomed_phrase_matcher(para.heading)) for bhc in bhcs[:3])\n",
    "findings_system_message = Message(\n",
    "    role=Role.SYSTEM,\n",
    "    content=f\"\"\"You are a consultant doctor completing a medical discharge summary.\n",
    "Your task is to list the main clinical findings made during the patient's stay.\n",
    "Each finding should be on a new line.\n",
    "Use Snomed CT preferred terms.\n",
    "This information can be found in the physician note provided by the user.\n",
    "\n",
    "The following are examples of previous patient's clinical findings:\n",
    "{examples}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_user_message =  Message(\n",
    "    role=Role.USER,\n",
    "    content=f\"\"\"Physician Note\n",
    "\n",
    "{sample_physician_notes.iloc[-1][\"TEXT\"]}\n",
    "Please write the list findings using the physician note and the requirements given in the system message.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_response = llm.query([findings_system_message, findings_user_message])\n",
    "gpt_findings = findings_response.content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_delimiter = \"\\n\" + (\"*\" * 80) + \"\\n\"\n",
    "output_strings = [f\"{message.role}\\n{message.content}\" for message in [findings_system_message, findings_user_message]]\n",
    "gpt_heading_strings = \"\\n\".join(sorted(gpt_findings))\n",
    "output_strings.append(f\"{Role.ASSISTANT}\\n{gpt_heading_strings}\")\n",
    "heading_strings = \"\\n\".join(sorted(para.heading for para in sample_bhc.problem_sections))\n",
    "output_strings.append(f\"Mimic Headings\\n{heading_strings}\")\n",
    "(EXAMPLE_DIR / \"findings.txt\").write_text(message_delimiter.join(output_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_cuis = [[span.label_ for span in finding_spans] for finding_spans in snomed_phrase_matcher.pipe(gpt_findings)]\n",
    "finding_to_cuis = {finding: cuis for finding, cuis in zip(gpt_findings, findings_cuis)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_phrase_matcher = SnomedPhraseMatcher(nlp, False)\n",
    "for cui in {cui for cuis in findings_cuis for cui in cuis}:\n",
    "    custom_phrase_matcher.add_parent_cui(int(cui), snomed_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_finding_cui = -1\n",
    "for finding, cuis in finding_to_cuis.items():\n",
    "    if not cuis:\n",
    "        custom_phrase_matcher._phrase_matcher.add(str(unmatched_finding_cui), [custom_phrase_matcher._nlp(finding)])\n",
    "        finding_to_cuis[finding] = [unmatched_finding_cui]\n",
    "        unmatched_finding_cui -= 1\n",
    "finding_to_cuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician_note_spans = custom_phrase_matcher.pipe(sample_physician_notes[\"TEXT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_to_spans = defaultdict(list)\n",
    "for note_idx, note_spans in enumerate(physician_note_spans):\n",
    "    for span in note_spans:\n",
    "        cui_to_spans[span.label_].append((note_idx, span))\n",
    "\n",
    "finding_to_spans = {\n",
    "    finding: [span for cui in cuis for span in cui_to_spans[cui]]\n",
    "    for finding, cuis in finding_to_cuis.items()\n",
    "}\n",
    "\n",
    "finding_to_spans = {cui: sorted(spans, key=lambda x: (x[0], x[1].start)) for cui, spans in finding_to_spans.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finding_to_spans_simplified = {\n",
    "    finding: [{\"text\":span.text, \"doc_idx\": doc_idx, \"start\": span.start, \"end\": span.end} for doc_idx, span in spans]\n",
    "    for finding, spans in finding_to_spans.items()\n",
    "}\n",
    "(EXAMPLE_DIR / \"retrieval.json\").write_text(json.dumps(finding_to_spans_simplified, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_bhc = list(spacy_tokenizer.pipe([bhc.assessment_and_plan for bhc in bhcs if bhc.assessment_and_plan]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.median([len(doc) for doc in tokenized_bhc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "spacy_tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp(\"\"\"Mr Known lastname 52368 is a 59M w HCV cirrhosis w grade II esophageal varices\n",
    "admitted w coffee-ground emesis and melena concerning for UGIB,\n",
    "s/p MICU stay for hypotension.\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
