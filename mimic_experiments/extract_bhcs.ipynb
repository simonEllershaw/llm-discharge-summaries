{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract BHCs\n",
    "\n",
    "1. Load Discharge Dataset\n",
    "2. Extract BHCs\n",
    "3. Run Snomed Phrase Matcher + evaluate misses\n",
    "5. Tune Snomed PhraseMatcher\n",
    "6. Save BHCs and Tuned Snomed Phrase Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.schemas.mimic import BHC, ProblemSection\n",
    "from discharge_summaries.snomed.lookup import SnomedLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "BHC_FPATH = MIMIC_III_DIR / \"BHCS.json\"\n",
    "\n",
    "SNOMED_DIR = Path.cwd().parent / \"data\" / \"snomed\"\n",
    "PHRASE_MATCHER_FPATH = SNOMED_DIR / \"snomed_phrase_matcher.pkl\"\n",
    "TUNED_PHRASE_MATCHER_FPATH = SNOMED_DIR / \"tuned_snomed_phrase_matcher.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Discharge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_summary_df = pd.read_csv(MIMIC_III_DIR / \"discharge_summaries_mimic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in discharge_summary_df.iloc[:5][\"BHC\"]:\n",
    "    print(text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract BHCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraph_splitting_regexes() -> Tuple[re.Pattern, re.Pattern]:\n",
    "    punctuation_prefix = \"[^A-Za-z]*\"\n",
    "    heading_regex = \"[A-Za-z][^\\n]*?\"\n",
    "    heading_delimiter = \"[-:][ \\n]\"\n",
    "    paragraph_text = \".*\"\n",
    "\n",
    "    paragraph_split_regex = re.compile(\n",
    "        f\"\\n\\n(?={punctuation_prefix}{heading_regex}{heading_delimiter})\"\n",
    "    )\n",
    "    heading_grouping_regex = re.compile(\n",
    "        f\"^{punctuation_prefix}({heading_regex}){heading_delimiter}({paragraph_text})\",\n",
    "        re.DOTALL,\n",
    "    )\n",
    "    return paragraph_split_regex, heading_grouping_regex\n",
    "\n",
    "\n",
    "def extract_bhcs_from_discharge_summaries(\n",
    "    discharge_summary_df: pd.DataFrame,\n",
    ") -> List[BHC]:\n",
    "    paragraph_split_regex, heading_grouping_regex = get_paragraph_splitting_regexes()\n",
    "    bhcs = []\n",
    "    for _, discharge_summary in tqdm(\n",
    "        discharge_summary_df.iterrows(), total=len(discharge_summary_df)\n",
    "    ):\n",
    "        paragraphs = re.split(paragraph_split_regex, str(discharge_summary[\"BHC\"]))\n",
    "\n",
    "        first_match = re.match(heading_grouping_regex, paragraphs[0])\n",
    "        if (\n",
    "            not first_match\n",
    "            or \"assessment\" in first_match.group(1).strip().lower()\n",
    "            or \"a/p\" in first_match.group(1).strip().lower()\n",
    "        ):\n",
    "            assessment_and_plan = paragraphs[0]\n",
    "        else:\n",
    "            assessment_and_plan = \"\"\n",
    "        problem_paragraph_start_idx = 1 if assessment_and_plan else 0\n",
    "\n",
    "        problem_sections = []\n",
    "        for para in paragraphs[problem_paragraph_start_idx:]:\n",
    "            match = re.match(heading_grouping_regex, para)\n",
    "            problem_sections.append(\n",
    "                ProblemSection(\n",
    "                    heading=match.group(1).strip() if match else \"\",\n",
    "                    text=match.group(2).strip() if match else para.strip(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        bhcs.append(\n",
    "            BHC(\n",
    "                hadm_id=int(discharge_summary[\"HADM_ID\"]),\n",
    "                full_text=str(discharge_summary[\"BHC\"]),\n",
    "                assessment_and_plan=assessment_and_plan,\n",
    "                problem_sections=problem_sections,\n",
    "            )\n",
    "        )\n",
    "    return bhcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhcs = extract_bhcs_from_discharge_summaries(discharge_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_bhcs = []\n",
    "incorrect_format_bhcs = []\n",
    "for bhc in bhcs:\n",
    "    if bhc.problem_sections and all(\n",
    "        problem_paragraph.heading for problem_paragraph in bhc.problem_sections\n",
    "    ):\n",
    "        valid_bhcs.append(bhc)\n",
    "    else:\n",
    "        incorrect_format_bhcs.append(bhc)\n",
    "len(valid_bhcs) / len(bhcs), len(valid_bhcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bhc in incorrect_format_bhcs[:10]:\n",
    "    print(bhc.full_text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bhc in valid_bhcs[:5]:\n",
    "    print(\"Full Text:\")\n",
    "    print(bhc.full_text)\n",
    "    print(\"---\")\n",
    "    print(\"Assessment and Plan:\")\n",
    "    print(bhc.assessment_and_plan)\n",
    "    print(\"Sections\")\n",
    "    for section in bhc.problem_sections:\n",
    "        print(\"---\")\n",
    "        print(section.heading)\n",
    "        print(section.text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run 'Vanilla' Snomed Phrase Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_phrase_matcher = pickle.loads(PHRASE_MATCHER_FPATH.read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = [para.heading for bhc in valid_bhcs for para in bhc.problem_sections]\n",
    "headings_snomed_spans = snomed_phrase_matcher.pipe(headings)\n",
    "missed_headings = [\n",
    "    heading.lower()\n",
    "    for heading, cuis in zip(headings, headings_snomed_spans)\n",
    "    if not cuis\n",
    "]\n",
    "1 - (len(missed_headings) / len(headings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value, count in Counter(missed_headings).most_common():\n",
    "    if count >= 15:\n",
    "        print(f\"{value}: {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tune Snomed Phrase Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_lookup = SnomedLookup.load(SNOMED_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra cuis that don't fall under previously defined parent cuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_parent_cuis = {\n",
    "    169443000,\n",
    "    311788003,\n",
    "    384760004,\n",
    "}\n",
    "print([snomed_lookup.cui_to_preferred_term[cui] for cui in extra_parent_cuis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parent_cui in tqdm(extra_parent_cuis):\n",
    "    snomed_phrase_matcher.add_parent_cui(parent_cui, snomed_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add obvious misses for any disorder/finding that occurs over 15 times in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_and_missing_synonyms = [\n",
    "    (365870005, \"Code\"),\n",
    "    (311788003, \"Access\"),\n",
    "    (384760004, \"FEN\"),  # Added as parent cui\n",
    "    # Access is a parent cui\n",
    "    (118231006, \"Communication\"),\n",
    "    (301113001, \"Rhythm\"),\n",
    "    (106063007, \"Pump\"),\n",
    "    (169443000, \"PPX\"),  # Added as parent cui\n",
    "    (73211009, \"Diabetes\"),\n",
    "    (102957003, \"Neuro\"),\n",
    "    (251015000, \"Coronaries\"),\n",
    "    (36456004, \"Dispo\"),\n",
    "    (384760004, \"Nutrition\"),\n",
    "    (106063007, \"CV\"),\n",
    "    (903081000000107, \"Contact\"),\n",
    "    (36456004, \"Disposition\"),\n",
    "    (118231006, \"Comm\"),\n",
    "    (160931000119108, \"Transaminitis\"),\n",
    "    (106048009, \"Pulmonary\"),  # ?\n",
    "    (44054006, \"DM2\"),\n",
    "    (299691001, \"Heme\"),\n",
    "    (49436004, \"Afib\"),\n",
    "    (401314000, \"NSTEMI\"),\n",
    "    (106176003, \"Endocrine\"),\n",
    "    (118238000, \"Renal\"),  # ?\n",
    "    (19943007, \"Cirrhosis\"),\n",
    "    (106048009, \"Respiratory\"),\n",
    "    (116367006, \"Psych\"),\n",
    "    (299691001, \"Hematology\"),\n",
    "    (419284004, \"AMS\"),\n",
    "    (301095005, \"Cardiac\"),\n",
    "    (74474003, \"GIB\"),\n",
    "    (166603001, \"Elevated LFTs\"),\n",
    "    (106048009, \"Resp\"),\n",
    "    (44054006, \"DMII\"),\n",
    "    (301120008, \"EKG changes\"),\n",
    "    # ('micu course', 30),\n",
    "    (444931001, \"Elevated troponin\"),\n",
    "    (106176003, \"Endo\"),\n",
    "    (191480000, \"ETOH withdrawal\"),\n",
    "    (37372002, \"UGIB\"),\n",
    "    # ('goals of care', 77),\n",
    "    # ('last name (un)', 25),\n",
    "    (401303003, \"STEMI\"),\n",
    "    (235856003, \"ESLD\"),\n",
    "    #  ('anticoagulation', 24),\n",
    "    (398137007, \"CRI\"),\n",
    "    (106048009, \"Pulm\"),\n",
    "    (233604007, \"PNA\"),\n",
    "    (106063007, \"Cardiovascular\"),\n",
    "    (284465006, \"Social\"),\n",
    "    (405729008, \"BRBPR\"),  # 5 letter acronym\n",
    "    (237840007, \"Anion gap\"),  # 3 different options here so chose parent\n",
    "    (721104000, \"Urosepsis\"),\n",
    "    (2776000, \"Delerium\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cui, missing_synonym in cui_and_missing_synonyms:\n",
    "    snomed_phrase_matcher._phrase_matcher.add(\n",
    "        str(cui), list(snomed_phrase_matcher._nlp.pipe([missing_synonym.lower()]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-evaluate misses with new fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings_snomed_spans_v2 = snomed_phrase_matcher.pipe(headings)\n",
    "missed_headings_v2 = [\n",
    "    heading.lower()\n",
    "    for heading, cuis in zip(headings, headings_snomed_spans_v2)\n",
    "    if not cuis\n",
    "]\n",
    "1 - len(missed_headings_v2) / len(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value, count in Counter(missed_headings_v2).most_common():\n",
    "    if count >= 15:\n",
    "        print(f\"{value}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bhc in valid_bhcs[:1000]:\n",
    "#     for idx, para in enumerate(bhc.problem_sections):\n",
    "#         if para.heading.lower() == \"cri\":\n",
    "#             print(idx, para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save BHCs and tuned snomed phrase matcher to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BHC_FPATH.write_text(json.dumps([bhc.dict() for bhc in valid_bhcs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNED_PHRASE_MATCHER_FPATH.write_bytes(pickle.dumps(snomed_phrase_matcher))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
