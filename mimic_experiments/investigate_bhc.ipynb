{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import List, Set\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens.span import Span\n",
    "\n",
    "from discharge_summaries.preprocessing.preprocess_snomed import Snomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "SNOMED_DIR = Path.cwd().parent / \"data\" / \"snomed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_summary_df = pd.read_csv(MIMIC_III_DIR / \"discharge_summaries_mimic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in discharge_summary_df.iloc[:5][\"BHC\"]:\n",
    "    print(text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed = Snomed.load(SNOMED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenizer = English().tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_snomed_matcher = snomed.get_phrase_matcher(\n",
    "    {\n",
    "        \"Clinical finding\",\n",
    "        \"Organism\",\n",
    "        \"Body structure, altered from its original anatomical structure\",\n",
    "    },\n",
    "    spacy_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subspan(sub_span: Span, span: Span) -> bool:\n",
    "    return span.start <= sub_span.start and span.end >= sub_span.end\n",
    "\n",
    "\n",
    "def filter_out_subspans(spans: List[Span]) -> List[Span]:\n",
    "    sorted_spans = sorted(\n",
    "        enumerate(spans), key=lambda idx_and_span: len(idx_and_span[1]), reverse=True\n",
    "    )\n",
    "    indices_to_keep: Set[int] = set()\n",
    "    for i, span in sorted_spans:\n",
    "        # Check if the span overlaps with any previously added spans\n",
    "        if all(not is_subspan(span, spans[j]) for j in indices_to_keep):\n",
    "            indices_to_keep.add(i)\n",
    "    return [spans[i] for i in indices_to_keep]\n",
    "\n",
    "\n",
    "def extract_snomed_cuis(heading: str, tokenizer, snomed_phrase_matcher) -> List[int]:\n",
    "    snomed_matches = snomed_phrase_matcher(tokenizer(heading), as_spans=True)\n",
    "    filtered_snomed_matches = filter_out_subspans(snomed_matches)\n",
    "    snomed_cuis = [int(span.label_) for span in filtered_snomed_matches]\n",
    "    return snomed_cuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"Mr Known lastname 52368 is a 59M w HCV cirrhosis w grade II esophageal varices\n",
    "admitted w coffee-ground emesis and melena concerning for UGIB,\n",
    "s/p MICU stay for hypotension.\n",
    "\n",
    "# UGIB: Pt did not have any more bleeds while in hospital. EGD\n",
    "revealed erythema and erosion in the antrum and pylorus\n",
    "compatible with non-steroidal induced gastritis. Pt did remember\n",
    "taking increased doses of naproxen for backache. Started on\n",
    "pantoprazole 40mg PO BID for one week with repeat endoscopy\n",
    "scheduled in one week (4-30). Recommended to take tylenol (max\n",
    "daily dose of 2gm) for pain instead of NSAIDs. Blood pressure\n",
    "meds were held at first, given MICU admission for hypotension,\n",
    "but were restarted on discharge.\n",
    "\n",
    "# HCV Cirrhosis: appears to be progressing to liver failure,\n",
    "with elevated INR at 1.6, decreased albumin at 2.6, tbili\n",
    "slightly elevated at 3.6, and chronic LE edema. Pt was continued\n",
    "on prophylactic medications.\n",
    "\n",
    "# FULL CODE\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in re.split(\n",
    "    r\"\\n\\n(?=(?:[^A-Za-z]*)(?:[A-Za-z][^\\n]*?)(?:[-\\.:][ \\n]))\",\n",
    "    discharge_summary_df[\"BHC\"][60],\n",
    "):\n",
    "    print(section[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_prefix = \"[^A-Za-z]*\"\n",
    "heading_regex = \"[A-Za-z][^\\n]*?\"\n",
    "heading_delimiter = \"[-:] \"\n",
    "paragraph_text = \".*\"\n",
    "\n",
    "paragraph_split_regex = re.compile(\n",
    "    f\"\\n\\n(?={punctuation_prefix}{heading_regex}{heading_delimiter})\"\n",
    ")\n",
    "heading_grouping_regex = re.compile(\n",
    "    f\"^{punctuation_prefix}({heading_regex}){heading_delimiter}({paragraph_text})\",\n",
    "    re.DOTALL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_split_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for section in (re.split(paragraph_split_regex, discharge_summary_df[\"BHC\"][80])):\n",
    "#     print(section)\n",
    "#     groups = re.match(heading_grouping_regex, section)\n",
    "#     if groups:\n",
    "#         print(groups.group(1))\n",
    "#         print(groups.group(2))\n",
    "#         print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemSection(BaseModel):\n",
    "    heading: str\n",
    "    text: str\n",
    "    snomed_heading_cuis: List[int]\n",
    "\n",
    "\n",
    "class BHC(BaseModel):\n",
    "    hadm_id: str\n",
    "    full_text: str\n",
    "    reason_for_admission: str\n",
    "    problem_sections: List[ProblemSection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhcs = []\n",
    "for _, discharge_summary in discharge_summary_df.iterrows():\n",
    "    paragraphs = re.split(paragraph_split_regex, str(discharge_summary[\"BHC\"]))\n",
    "\n",
    "    if re.match(heading_grouping_regex, paragraphs[0]):\n",
    "        reason_for_admission = \"\"\n",
    "        problem_paragraph_start_idx = 0\n",
    "    else:\n",
    "        reason_for_admission = paragraphs[0]\n",
    "        problem_paragraph_start_idx = 1\n",
    "\n",
    "    problem_sections = []\n",
    "    for para in paragraphs[problem_paragraph_start_idx:]:\n",
    "        match = re.match(heading_grouping_regex, para)\n",
    "        if match:\n",
    "            heading = match.group(1).strip()\n",
    "            heading_snomed_cuis = extract_snomed_cuis(\n",
    "                heading, spacy_tokenizer, whole_snomed_matcher\n",
    "            )\n",
    "            problem_sections.append(\n",
    "                ProblemSection(\n",
    "                    heading=heading,\n",
    "                    text=match.group(2).strip(),\n",
    "                    snomed_heading_cuis=heading_snomed_cuis,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            problem_sections.append(\n",
    "                ProblemSection(heading=\"\", text=para.strip(), snomed_heading_cuis=[])\n",
    "            )\n",
    "    bhcs.append(\n",
    "        BHC(\n",
    "            hadm_id=str(discharge_summary[\"HADM_ID\"]),\n",
    "            full_text=str(discharge_summary[\"BHC\"]),\n",
    "            reason_for_admission=reason_for_admission,\n",
    "            problem_sections=problem_sections,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_bhcs = []\n",
    "incorrect_format_bhcs = []\n",
    "for bhc in bhcs:\n",
    "    num_problem_paragraphs_w_heading = sum(\n",
    "        1 for problem_paragraph in bhc.problem_sections if problem_paragraph.heading\n",
    "    )\n",
    "    if (\n",
    "        num_problem_paragraphs_w_heading > 0\n",
    "        and num_problem_paragraphs_w_heading >= len(bhc.problem_sections) / 2\n",
    "    ):\n",
    "        valid_bhcs.append(bhc)\n",
    "    else:\n",
    "        incorrect_format_bhcs.append(bhc)\n",
    "len(valid_bhcs), len(incorrect_format_bhcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bhc in incorrect_format_bhcs[:10]:\n",
    "    print(bhc.full_text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bhc in valid_bhcs[20:30]:\n",
    "    print(bhc.full_text)\n",
    "    print(\"---\")\n",
    "    print(bhc.reason_for_admission)\n",
    "    for section in bhc.problem_sections:\n",
    "        print(\"---\")\n",
    "        print(section.heading)\n",
    "        print(section.text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_heading = []\n",
    "para_count = 0\n",
    "for bhc in valid_bhcs:\n",
    "    for para in bhc.problem_sections:\n",
    "        if not para.snomed_heading_cuis:\n",
    "            missed_heading.append(para.heading)\n",
    "    para_count += len(bhc.problem_sections)\n",
    "len(missed_heading) / para_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(missed_heading).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synonyms_of_interest_df = snomed.synonyms_df[\n",
    "#     snomed.synonyms_df[\"cui\"].isin(cuis_of_interest)\n",
    "# ]\n",
    "# len(synonyms_of_interest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_missing_synonyms(\n",
    "#     missing_cui_and_synonyms: List[Tuple[str, str]], synonyms_df\n",
    "# ) -> None:\n",
    "#     missing_synonyms_df = pd.DataFrame.from_records(\n",
    "#         missing_cui_and_synonyms, columns=synonyms_df.columns\n",
    "#     )\n",
    "#     synonyms_df = pd.concat([synonyms_df, missing_synonyms_df], ignore_index=True)\n",
    "#     synonyms_df.drop_duplicates(inplace=True)\n",
    "#     return synonyms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cui_and_missing_synonyms = [\n",
    "#     (\"384760004\", \"FEN\"),\n",
    "#     # (\"365870005\", \"Code Status\"),\n",
    "#     # (\"365870005\", \"Code\"),\n",
    "#     (\"73211009\", \"Diabetes\"),\n",
    "#     (\"73211009\", \"DM\"),  # Acryonym but shorter than 2 characters\n",
    "#     (\"44054006\", \"DM2\"),\n",
    "#     (\"169443000\", \"PPX\"),\n",
    "#     # (\"432138007\", \"Communication\"),\n",
    "#     # (\"432138007\", \"Comm\"),\n",
    "#     # (\"726711005\", \"Dispo\"),\n",
    "#     (\"74474003\", \"GI Bleed\"),\n",
    "#     (\"160931000119108\", \"transaminitis\"),\n",
    "#     (\"49436004\", \"Afib\"),\n",
    "#     (\"19943007\", \"Cirrhosis\"),\n",
    "#     (\"74474003\", \"GIB\"),\n",
    "#     # (\"386661006\", \"Fevers\"),\n",
    "#     # (\"91175000\", \"Seizures\"),\n",
    "#     # (\"311788003\", \"Access\"),\n",
    "#     # (\"251149006\", \"Rhythm\"),\n",
    "#     # (\"739122008\", \"Pump\"),\n",
    "# ]\n",
    "# synonyms_of_interest_df = add_missing_synonyms(\n",
    "#     cui_and_missing_synonyms, synonyms_of_interest_df\n",
    "# )\n",
    "# [(snomed.get_preferred_term(cui), synonym) for cui, synonym in cui_and_missing_synonyms]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
