{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from discharge_summaries.snomed.lookup import SnomedLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = (\n",
    "    Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    ")\n",
    "SNOMED_DIR = Path.cwd().parent / \"data\" / \"snomed\"\n",
    "PHRASE_MATCHER_FPATH = SNOMED_DIR / \"snomed_phrase_matcher.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_summary_df = pd.read_csv(MIMIC_III_DIR / \"discharge_summaries_mimic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_phrase_matcher = pickle.loads(PHRASE_MATCHER_FPATH.read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in discharge_summary_df.iloc[:5][\"BHC\"]:\n",
    "    print(text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_prefix = \"[^A-Za-z]*\"\n",
    "heading_regex = \"[A-Za-z][^\\n]*?\"\n",
    "heading_delimiter = \"[-:] \"\n",
    "paragraph_text = \".*\"\n",
    "\n",
    "paragraph_split_regex = re.compile(\n",
    "    f\"\\n\\n(?={punctuation_prefix}{heading_regex}{heading_delimiter})\"\n",
    ")\n",
    "heading_grouping_regex = re.compile(\n",
    "    f\"^{punctuation_prefix}({heading_regex}){heading_delimiter}({paragraph_text})\",\n",
    "    re.DOTALL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemSection(BaseModel):\n",
    "    heading: str\n",
    "    text: str\n",
    "    snomed_heading_cuis: List[int]\n",
    "\n",
    "\n",
    "class BHC(BaseModel):\n",
    "    hadm_id: str\n",
    "    full_text: str\n",
    "    reason_for_admission: str\n",
    "    problem_sections: List[ProblemSection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhcs = []\n",
    "for _, discharge_summary in tqdm(\n",
    "    discharge_summary_df.iterrows(), total=len(discharge_summary_df)\n",
    "):\n",
    "    paragraphs = re.split(paragraph_split_regex, str(discharge_summary[\"BHC\"]))\n",
    "\n",
    "    first_match = re.match(heading_grouping_regex, paragraphs[0])\n",
    "    if (\n",
    "        not first_match\n",
    "        or \"assessment\" in first_match.group(1).strip().lower()\n",
    "        or \"a/p\" in first_match.group(1).strip().lower()\n",
    "    ):\n",
    "        reason_for_admission = paragraphs[0]\n",
    "    else:\n",
    "        reason_for_admission = \"\"\n",
    "    problem_paragraph_start_idx = 1 if reason_for_admission else 0\n",
    "\n",
    "    headings, texts = [], []\n",
    "    for para in paragraphs[problem_paragraph_start_idx:]:\n",
    "        match = re.match(heading_grouping_regex, para)\n",
    "        headings.append(match.group(1).strip() if match else \"\")\n",
    "        texts.append(match.group(2).strip() if match else para.strip())\n",
    "    heading_snomed_cuis = snomed_phrase_matcher.pipe(headings)\n",
    "    problem_sections = [\n",
    "        ProblemSection(heading=h, text=t, snomed_heading_cuis=cuis)\n",
    "        for h, t, cuis in zip(headings, texts, heading_snomed_cuis)\n",
    "    ]\n",
    "\n",
    "    bhcs.append(\n",
    "        BHC(\n",
    "            hadm_id=str(discharge_summary[\"HADM_ID\"]),\n",
    "            full_text=str(discharge_summary[\"BHC\"]),\n",
    "            reason_for_admission=reason_for_admission,\n",
    "            problem_sections=problem_sections,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_bhcs = []\n",
    "incorrect_format_bhcs = []\n",
    "for bhc in bhcs:\n",
    "    num_problem_paragraphs_w_heading = sum(\n",
    "        1 for problem_paragraph in bhc.problem_sections if problem_paragraph.heading\n",
    "    )\n",
    "    if num_problem_paragraphs_w_heading > len(bhc.problem_sections) / 2:\n",
    "        valid_bhcs.append(bhc)\n",
    "    else:\n",
    "        incorrect_format_bhcs.append(bhc)\n",
    "len(valid_bhcs), len(incorrect_format_bhcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bhc in incorrect_format_bhcs[:10]:\n",
    "    print(bhc.full_text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bhc in valid_bhcs[20:30]:\n",
    "    print(\"Full Text:\")\n",
    "    print(bhc.full_text)\n",
    "    print(\"---\")\n",
    "    print(\"Reason for Admission:\")\n",
    "    print(bhc.reason_for_admission)\n",
    "    print(\"Sections\")\n",
    "    for section in bhc.problem_sections:\n",
    "        print(\"---\")\n",
    "        print(section.heading)\n",
    "        print(section.text)\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_heading = []\n",
    "para_count = 0\n",
    "for bhc in valid_bhcs:\n",
    "    for para in bhc.problem_sections:\n",
    "        if not para.snomed_heading_cuis:\n",
    "            missed_heading.append(para.heading)\n",
    "    para_count += len(bhc.problem_sections)\n",
    "len(missed_heading) / para_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(missed_heading).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOMED_DIR = Path.cwd().parent / \"data\" / \"snomed\"\n",
    "snomed_lookup = SnomedLookup.load(SNOMED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_parent_cuis = {\n",
    "    169443000,\n",
    "    311788003,\n",
    "    384760004,\n",
    "}\n",
    "print([snomed_lookup.cui_to_preferred_term[cui] for cui in extra_parent_cuis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_and_missing_synonyms = [\n",
    "    (365870005, \"Code\"),\n",
    "    (311788003, \"Access\"),\n",
    "    (384760004, \"FEN\"),  # Added as parent cui\n",
    "    # Access is a parent cui\n",
    "    (118231006, \"Communication\"),\n",
    "    (301113001, \"Rhythm\"),\n",
    "    (106063007, \"Pump\"),\n",
    "    (169443000, \"PPX\"),  # Added as parent cui\n",
    "    (73211009, \"Diabetes\"),\n",
    "    (102957003, \"Neuro\"),\n",
    "    (251015000, \"Coronaries\"),\n",
    "    (36456004, \"Dispo\"),\n",
    "    (384760004, \"Nutrition\"),\n",
    "    (106063007, \"CV\"),\n",
    "    (903081000000107, \"Contact\"),\n",
    "    (36456004, \"Disposition\"),\n",
    "    (118231006, \"Comm\"),\n",
    "    (160931000119108, \"Transaminitis\"),\n",
    "    (106048009, \"Pulmonary\"),  # ?\n",
    "    (44054006, \"DM2\"),\n",
    "    (299691001, \"Heme\"),\n",
    "    (49436004, \"Afib\"),\n",
    "    (401314000, \"NSTEMI\"),\n",
    "    (106176003, \"Endocrine\"),\n",
    "    (118238000, \"Renal\"),  # ?\n",
    "    (19943007, \"Cirrhosis\"),\n",
    "    (106048009, \"Respiratory\"),\n",
    "    (116367006, \"Psych\"),\n",
    "    (299691001, \"Hematology\"),\n",
    "    (419284004, \"AMS\"),\n",
    "    (301095005, \"Cardiac\"),\n",
    "    (74474003, \"GIB\"),\n",
    "    (166603001, \"Elevated LFTs\"),\n",
    "    (106048009, \"Resp\"),\n",
    "    (44054006, \"DMII\"),\n",
    "    (301120008, \"EKG changes\"),\n",
    "    # ('micu course', 30),\n",
    "    (444931001, \"Elevated troponin\"),\n",
    "    (106176003, \"Endo\"),\n",
    "    (191480000, \"ETOH withdrawal\"),\n",
    "    (37372002, \"UGIB\"),\n",
    "    # ('goals of care', 77),\n",
    "    # ('last name (un)', 25),\n",
    "    (401303003, \"STEMI\"),\n",
    "    (235856003, \"ESLD\"),\n",
    "    #  ('anticoagulation', 24),\n",
    "    (398137007, \"CRI\"),\n",
    "    (106048009, \"Pulm\"),\n",
    "    (233604007, \"PNA\"),\n",
    "    (106063007, \"Cardiovascular\"),\n",
    "    (284465006, \"Social\"),\n",
    "    (405729008, \"BRBPR\"),  # 5 letter acronym\n",
    "    (237840007, \"Anion gap\"),  # 3 different options here so chose parent\n",
    "    (721104000, \"Urosepsis\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_child_cuis = True\n",
    "cui_to_synonyms_lower = {}\n",
    "for parent_cui in extra_parent_cuis:\n",
    "    parent_synonyms = {\n",
    "        synonym.lower()\n",
    "        for synonym in snomed_lookup.cui_to_synonyms.get(parent_cui, set())\n",
    "    }\n",
    "    if not parent_synonyms:\n",
    "        raise ValueError(f\"Parent CUI {parent_cui} has no synonyms\")\n",
    "    cui_to_synonyms_lower[parent_cui] = parent_synonyms\n",
    "\n",
    "    for child_cui in snomed_lookup.get_child_cuis(parent_cui):\n",
    "        child_synonyms = {\n",
    "            synonym.lower()\n",
    "            for synonym in snomed_lookup.cui_to_synonyms.get(child_cui, set())\n",
    "        }\n",
    "        if keep_child_cuis:\n",
    "            cui_to_synonyms_lower[child_cui] = child_synonyms\n",
    "        else:\n",
    "            cui_to_synonyms_lower[parent_cui].union(child_synonyms)\n",
    "\n",
    "for cui, synonyms_lower in tqdm(cui_to_synonyms_lower.items()):\n",
    "    snomed_phrase_matcher._phrase_matcher.add(\n",
    "        str(cui), list(snomed_phrase_matcher._nlp.pipe(synonyms_lower))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cui, missing_synonym in cui_and_missing_synonyms:\n",
    "    snomed_phrase_matcher._phrase_matcher.add(\n",
    "        str(cui), list(snomed_phrase_matcher._nlp.pipe([missing_synonym.lower()]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = [para.heading for bhc in valid_bhcs for para in bhc.problem_sections]\n",
    "snomed_codes = snomed_phrase_matcher.pipe(headings)\n",
    "missed_headings = [\n",
    "    heading.lower() for heading, cuis in zip(headings, snomed_codes) if not cuis\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missed_headings) / len(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(missed_headings).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bhc in valid_bhcs[:1000]:\n",
    "    for idx, para in enumerate(bhc.problem_sections):\n",
    "        if para.heading.lower() == \"cri\":\n",
    "            print(idx, para)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
