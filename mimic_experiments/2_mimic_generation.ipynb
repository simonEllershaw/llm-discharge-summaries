{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC Generation\n",
    "\n",
    "This notebooks ingests mimic physician notes and Royal College of Physician London guidelines. \n",
    "\n",
    "These are converted into a prompt and queried to GPT-4-turbo. \n",
    "\n",
    "The simplified json schema used in the prompt is saved to file.\n",
    "\n",
    "The outputs are then saved to `outputs\\llm_responses` dir. This output is the raw json and the message history with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from random import Random\n",
    "\n",
    "import jsonschema\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai.error import RateLimitError\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from llm_discharge_summaries.openai_llm.chat_models import AzureOpenAIChatModel\n",
    "from llm_discharge_summaries.openai_llm.message import Message, Role\n",
    "from llm_discharge_summaries.openai_llm.prompts import (\n",
    "    generate_rcp_system_message,\n",
    "    generate_rcp_user_message,\n",
    ")\n",
    "from llm_discharge_summaries.schemas.mimic import PhysicianNote\n",
    "from llm_discharge_summaries.schemas.rcp_guidelines import RCPGuidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_III_DIR = Path.cwd() / \"inputs\" / \"physionet.org\" / \"files\" / \"mimiciii\" / \"1.4\"\n",
    "PHYSICIAN_NOTE_FPATH = MIMIC_III_DIR / \"physician_notes_mimic.csv\"\n",
    "ONE_SHOT_EXAMPLE_DIR = (\n",
    "    Path.cwd().parent / \"llm_discharge_summaries\" / \"schemas\" / \"rcp_one_shot_example\"\n",
    ")\n",
    "OUTPUT_DIR = Path.cwd() / \"outputs\" / \"llm_responses\"\n",
    "\n",
    "GPT_4_ENGINE = \"gpt-4-turbo\"\n",
    "AZURE_API_VERSION = \"2023-07-01-preview\"\n",
    "TOKENIZER_NAME = \"cl100k_base\"\n",
    "\n",
    "NUMBER_CLINICAL_EVALUATORS = 15\n",
    "NUM_EXAMPLES_PER_EVALUATOR = 5\n",
    "RANDOM_SEED = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_schema = RCPGuidelines.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title, required fields are removed as contain redundant information. \n",
    "\n",
    "Definition properties with a default value are also removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_keys_recursive(d: list | dict, keys: set[str]):\n",
    "    if isinstance(d, dict):\n",
    "        for key in list(d.keys()):\n",
    "            if key in keys:\n",
    "                del d[key]\n",
    "            else:\n",
    "                remove_keys_recursive(d[key], keys)\n",
    "    elif isinstance(d, list):\n",
    "        for item in d:\n",
    "            remove_keys_recursive(item, keys)\n",
    "    return d\n",
    "\n",
    "\n",
    "def remove_default_definition_properties(schema: dict):\n",
    "    for section_dict in schema[\"definitions\"].values():\n",
    "        section_dict[\"properties\"] = {\n",
    "            property: property_dict\n",
    "            for property, property_dict in section_dict[\"properties\"].items()\n",
    "            if \"default\" not in property_dict.keys()\n",
    "        }\n",
    "    return schema\n",
    "\n",
    "\n",
    "simplified_rcp_schema = remove_keys_recursive(\n",
    "    deepcopy(rcp_schema), {\"title\", \"required\"}\n",
    ")\n",
    "simplified_rcp_schema = remove_default_definition_properties(simplified_rcp_schema)\n",
    "(OUTPUT_DIR / \"simplified_rcp_schema.json\").write_text(\n",
    "    json.dumps(simplified_rcp_schema, indent=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 1 shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_notes = [\n",
    "    PhysicianNote(**note)\n",
    "    for note in json.loads((ONE_SHOT_EXAMPLE_DIR / \"physician_notes.json\").read_text())\n",
    "]\n",
    "example_response = json.loads(\n",
    "    (ONE_SHOT_EXAMPLE_DIR / \"discharge_summary.json\").read_text()\n",
    ")\n",
    "jsonschema.validate(example_response, rcp_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = generate_rcp_system_message(simplified_rcp_schema)\n",
    "one_shot_user_message = generate_rcp_user_message(example_notes)\n",
    "one_shot_response_message = Message(\n",
    "    role=Role.ASSISTANT, content=json.dumps(example_response)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly sample admission examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = pd.read_csv(PHYSICIAN_NOTE_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shared_examples = math.floor(NUMBER_CLINICAL_EVALUATORS / 2)\n",
    "eval_sample_size = (\n",
    "    NUM_EXAMPLES_PER_EVALUATOR * NUMBER_CLINICAL_EVALUATORS - num_shared_examples\n",
    ")\n",
    "eval_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm_ids = notes_df[\"HADM_ID\"].unique().tolist()\n",
    "# Used for 1 round of qualitative evaluation\n",
    "eval_hadm_ids = Random(RANDOM_SEED).sample(\n",
    "    hadm_ids, NUM_EXAMPLES_PER_EVALUATOR + eval_sample_size\n",
    ")[NUM_EXAMPLES_PER_EVALUATOR:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAIChatModel(\n",
    "    api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=AZURE_API_VERSION,\n",
    "    engine=GPT_4_ENGINE,\n",
    "    temperature=0,\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hadm_id in tqdm(eval_hadm_ids):\n",
    "    hadm_id_output_dir = OUTPUT_DIR / str(int(hadm_id))\n",
    "    hadm_id_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    physician_notes = [\n",
    "        PhysicianNote(\n",
    "            hadm_id=row[\"HADM_ID\"],\n",
    "            title=row[\"DESCRIPTION\"],\n",
    "            timestamp=row[\"CHARTTIME\"],\n",
    "            text=row[\"TEXT\"],\n",
    "        )\n",
    "        for _, row in notes_df[notes_df[\"HADM_ID\"] == hadm_id].iterrows()\n",
    "    ]\n",
    "\n",
    "    user_message = generate_rcp_user_message(physician_notes)\n",
    "    prompt = [\n",
    "        system_message,\n",
    "        one_shot_user_message,\n",
    "        one_shot_response_message,\n",
    "        user_message,\n",
    "    ]\n",
    "\n",
    "    # Very basic handling of rate limit errors\n",
    "    generation_complete = False\n",
    "    while not generation_complete:\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            response = llm.query(prompt)\n",
    "            time_taken = time.time() - t0\n",
    "            generation_complete = True\n",
    "        except RateLimitError:\n",
    "            print(\"Rate limit exceeded\")\n",
    "            time.sleep(20)\n",
    "\n",
    "    raw_messages = (\"\\n\" + \"*\" * 80 + \"\\n\").join(\n",
    "        [message.content for message in prompt]\n",
    "        + [\n",
    "            response.content,\n",
    "            f\"Time taken: {time_taken}\",\n",
    "        ]\n",
    "    )\n",
    "    (hadm_id_output_dir / \"raw_messages.txt\").write_text(raw_messages)\n",
    "\n",
    "    # Handle prefix and suffixes e.g. '''json...'''\n",
    "    json_start = response.content.find(\"{\")\n",
    "    json_end = response.content.rfind(\"}\")\n",
    "    (hadm_id_output_dir / \"discharge_summary.json\").write_text(\n",
    "        json.dumps(json.loads(response.content[json_start : json_end + 1]), indent=4)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
