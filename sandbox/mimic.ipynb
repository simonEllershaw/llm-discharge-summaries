{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 23\n",
    "MIMIC_DIR = Path.cwd().parent / \"data\" / \"physionet.org\" / \"files\"\n",
    "\n",
    "MIMIC_III_DIR = MIMIC_DIR / \"mimiciii\" / \"1.4\"\n",
    "MIMIC_IV_DIR = MIMIC_DIR / \"mimiciv\" / \"2.2\" / \"note\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in MIMIC III notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(MIMIC_III_DIR / \"NOTEEVENTS.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing\n",
    "\n",
    "Remove error and duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"ISERROR\"] != 1]\n",
    "df.drop(\"ISERROR\", axis=1, inplace=True)\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df[\"HADM_ID\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only Physician and discharge notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CATEGORY\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    (df[\"CATEGORY\"] == \"Physician \")\n",
    "    | ((df[\"CATEGORY\"] == \"Discharge summary\") & (df[\"DESCRIPTION\"] == \"Report\"))\n",
    "]\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by HADM_ID and only keep rows with both a discharge summary and physician note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(\"HADM_ID\")\n",
    "grouped_df = grouped_df.filter(lambda group: len(group[\"CATEGORY\"].unique()) == 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text, fillna chartimes with date and midnight (to allow sorting by time), then regroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    cleaned_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    cleaned_text = re.sub(r\"\\n {2,}\", \"\\n\", cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "grouped_df[\"CHARTTIME\"] = grouped_df[\"CHARTTIME\"].fillna(df[\"CHARTDATE\"] + \" 23:59:59\")\n",
    "grouped_df[\"TEXT\"] = grouped_df[\"TEXT\"].apply(lambda text: clean_text(text))\n",
    "grouped_df = grouped_df.groupby(\"HADM_ID\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test train split, currently v large test size as train data needed for method validation rather than model training currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys, test_keys = train_test_split(\n",
    "    list(grouped_df.groups.keys()), test_size=0.8, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = [grouped_df.get_group(key) for key in train_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dfs[0]\n",
    "sample = sample.sort_values(\"CHARTTIME\")\n",
    "display(sample)  # type: ignore\n",
    "for _, row in sample.iterrows():\n",
    "    print(\"=\" * 80)\n",
    "    print(row[\"CATEGORY\"])\n",
    "    print(row[\"TEXT\"])\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cleaned dataframe\n",
    "\n",
    "Create dataframe with all physcian notes concatenated together (ordered in time), the brief hospital course as the summary and hadim if linking is needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_continuous_physician_note(df: pd.DataFrame) -> str:\n",
    "    notes_df = df[df[\"CATEGORY\"] != \"Discharge summary\"]\n",
    "    notes_df = notes_df.sort_values(\"CHARTDATE\")\n",
    "    notes = notes_df[\"TEXT\"].values\n",
    "    notes = [f\"Physician Note {idx}:\\n{note}\" for idx, note in enumerate(notes)]\n",
    "    return \"\\n****\\n\".join(notes)\n",
    "\n",
    "\n",
    "def extract_brief_hospital_course(df: pd.DataFrame) -> str:\n",
    "    full_summary = df[df[\"CATEGORY\"] == \"Discharge summary\"][\"TEXT\"].values[0]\n",
    "    start_pattern = r\"\\nBrief Hospital Course:\\n\"\n",
    "    end_pattern = r\"\\nMedications on Admission:\\n\"\n",
    "    match = re.search(f\"{start_pattern}(.*?){end_pattern}\", full_summary, re.DOTALL)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "\n",
    "physician_notes = [create_continuous_physician_note(df) for df in train_dfs]\n",
    "brief_hospital_courses = [extract_brief_hospital_course(df) for df in train_dfs]\n",
    "hadim_ids = [df[\"HADM_ID\"].values[0] for df in train_dfs]\n",
    "cleaned_df = pd.DataFrame.from_dict(\n",
    "    {\"notes\": physician_notes, \"summary\": brief_hospital_courses, \"hadim\": hadim_ids}\n",
    ")\n",
    "# Remove empty summaries\n",
    "cleaned_df = cleaned_df[cleaned_df[\"summary\"] != \"\"]\n",
    "cleaned_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "note_tokens = cleaned_df[\"notes\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "summary_tokens = cleaned_df[\"summary\"].apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = pd.concat(\n",
    "    [note_tokens.describe(), summary_tokens.describe()], axis=1\n",
    ").transpose()\n",
    "tokens_df = tokens_df.drop(\"count\", axis=1)\n",
    "tokens_df.loc[\"total\"] = tokens_df.sum(numeric_only=True)\n",
    "tokens_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
